{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint アンサンブル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
      "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
      "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
      "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
      "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
      "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
      "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
      "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
      "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
      "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
      "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
      "       'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710</td>\n",
       "      <td>2003</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1786</td>\n",
       "      <td>2001</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1717</td>\n",
       "      <td>1915</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2198</td>\n",
       "      <td>2000</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1362</td>\n",
       "      <td>1993</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1694</td>\n",
       "      <td>2004</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2090</td>\n",
       "      <td>1973</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1774</td>\n",
       "      <td>1931</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1077</td>\n",
       "      <td>1939</td>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1040</td>\n",
       "      <td>1965</td>\n",
       "      <td>129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2324</td>\n",
       "      <td>2005</td>\n",
       "      <td>345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>912</td>\n",
       "      <td>1962</td>\n",
       "      <td>144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1494</td>\n",
       "      <td>2006</td>\n",
       "      <td>279500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1253</td>\n",
       "      <td>1960</td>\n",
       "      <td>157000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>854</td>\n",
       "      <td>1929</td>\n",
       "      <td>132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1004</td>\n",
       "      <td>1970</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1296</td>\n",
       "      <td>1967</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1114</td>\n",
       "      <td>2004</td>\n",
       "      <td>159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1339</td>\n",
       "      <td>1958</td>\n",
       "      <td>139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2376</td>\n",
       "      <td>2005</td>\n",
       "      <td>325300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1108</td>\n",
       "      <td>1930</td>\n",
       "      <td>139400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1795</td>\n",
       "      <td>2002</td>\n",
       "      <td>230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1060</td>\n",
       "      <td>1976</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1060</td>\n",
       "      <td>1968</td>\n",
       "      <td>154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1600</td>\n",
       "      <td>2007</td>\n",
       "      <td>256300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>900</td>\n",
       "      <td>1951</td>\n",
       "      <td>134800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1704</td>\n",
       "      <td>2007</td>\n",
       "      <td>306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1600</td>\n",
       "      <td>1957</td>\n",
       "      <td>207500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>520</td>\n",
       "      <td>1927</td>\n",
       "      <td>68500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>1838</td>\n",
       "      <td>2005</td>\n",
       "      <td>192140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>958</td>\n",
       "      <td>1976</td>\n",
       "      <td>143750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>968</td>\n",
       "      <td>1927</td>\n",
       "      <td>64500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>1792</td>\n",
       "      <td>2000</td>\n",
       "      <td>186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1126</td>\n",
       "      <td>1977</td>\n",
       "      <td>160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1537</td>\n",
       "      <td>1962</td>\n",
       "      <td>174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>864</td>\n",
       "      <td>1971</td>\n",
       "      <td>120500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1932</td>\n",
       "      <td>2008</td>\n",
       "      <td>394617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1236</td>\n",
       "      <td>1957</td>\n",
       "      <td>149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>1725</td>\n",
       "      <td>1979</td>\n",
       "      <td>197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>2555</td>\n",
       "      <td>1922</td>\n",
       "      <td>191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>848</td>\n",
       "      <td>2004</td>\n",
       "      <td>149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>952</td>\n",
       "      <td>1916</td>\n",
       "      <td>121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1422</td>\n",
       "      <td>2004</td>\n",
       "      <td>179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>913</td>\n",
       "      <td>1966</td>\n",
       "      <td>129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>1188</td>\n",
       "      <td>1962</td>\n",
       "      <td>157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>2090</td>\n",
       "      <td>1995</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>1346</td>\n",
       "      <td>1910</td>\n",
       "      <td>112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>630</td>\n",
       "      <td>1970</td>\n",
       "      <td>92000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>1792</td>\n",
       "      <td>1974</td>\n",
       "      <td>136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1578</td>\n",
       "      <td>2008</td>\n",
       "      <td>287090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>1072</td>\n",
       "      <td>2005</td>\n",
       "      <td>145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>1140</td>\n",
       "      <td>2006</td>\n",
       "      <td>84500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1221</td>\n",
       "      <td>2004</td>\n",
       "      <td>185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1647</td>\n",
       "      <td>1999</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2073</td>\n",
       "      <td>1978</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2340</td>\n",
       "      <td>1941</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1078</td>\n",
       "      <td>1950</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1256</td>\n",
       "      <td>1965</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GrLivArea  YearBuilt  SalePrice\n",
       "0          1710       2003     208500\n",
       "1          1262       1976     181500\n",
       "2          1786       2001     223500\n",
       "3          1717       1915     140000\n",
       "4          2198       2000     250000\n",
       "5          1362       1993     143000\n",
       "6          1694       2004     307000\n",
       "7          2090       1973     200000\n",
       "8          1774       1931     129900\n",
       "9          1077       1939     118000\n",
       "10         1040       1965     129500\n",
       "11         2324       2005     345000\n",
       "12          912       1962     144000\n",
       "13         1494       2006     279500\n",
       "14         1253       1960     157000\n",
       "15          854       1929     132000\n",
       "16         1004       1970     149000\n",
       "17         1296       1967      90000\n",
       "18         1114       2004     159000\n",
       "19         1339       1958     139000\n",
       "20         2376       2005     325300\n",
       "21         1108       1930     139400\n",
       "22         1795       2002     230000\n",
       "23         1060       1976     129900\n",
       "24         1060       1968     154000\n",
       "25         1600       2007     256300\n",
       "26          900       1951     134800\n",
       "27         1704       2007     306000\n",
       "28         1600       1957     207500\n",
       "29          520       1927      68500\n",
       "...         ...        ...        ...\n",
       "1430       1838       2005     192140\n",
       "1431        958       1976     143750\n",
       "1432        968       1927      64500\n",
       "1433       1792       2000     186500\n",
       "1434       1126       1977     160000\n",
       "1435       1537       1962     174000\n",
       "1436        864       1971     120500\n",
       "1437       1932       2008     394617\n",
       "1438       1236       1957     149700\n",
       "1439       1725       1979     197000\n",
       "1440       2555       1922     191000\n",
       "1441        848       2004     149300\n",
       "1442       2007       2008     310000\n",
       "1443        952       1916     121000\n",
       "1444       1422       2004     179600\n",
       "1445        913       1966     129000\n",
       "1446       1188       1962     157900\n",
       "1447       2090       1995     240000\n",
       "1448       1346       1910     112000\n",
       "1449        630       1970      92000\n",
       "1450       1792       1974     136000\n",
       "1451       1578       2008     287090\n",
       "1452       1072       2005     145000\n",
       "1453       1140       2006      84500\n",
       "1454       1221       2004     185000\n",
       "1455       1647       1999     175000\n",
       "1456       2073       1978     210000\n",
       "1457       2340       1941     266500\n",
       "1458       1078       1950     142125\n",
       "1459       1256       1965     147500\n",
       "\n",
       "[1460 rows x 3 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_price = pd.read_csv('C:/Users/miyas/kaggle/train.csv')\n",
    "print(house_price.columns)\n",
    "house_price.loc[:,['GrLivArea','YearBuilt','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用するデータのみにする\n",
    "X = house_price.loc[:,['GrLivArea','YearBuilt']].values\n",
    "y = house_price.SalePrice.values\n",
    "\n",
    "# StandardScalerを使うとintをfloatに変えたっていう警告が出るので，先に変えておく．\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "\n",
    "# trainデータとtestデータに分ける\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "# 標準化\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "sc.fit(y_train[:,np.newaxis])\n",
    "y_train_std = sc.transform(y_train[:,np.newaxis]).flatten()\n",
    "y_test_std = sc.transform(y_test[:,np.newaxis]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_shape: (1168, 2)\n",
      "y_train_shape: (1168,)\n",
      "X_test_shape: (292, 2)\n",
      "y_test_shape: (292,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train_shape:',X_train_std.shape)\n",
    "print('y_train_shape:',y_train_std.shape)\n",
    "print('X_test_shape:',X_test_std.shape)\n",
    "print('y_test_shape:',y_test_std.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】ブレンディングのスクラッチ実装\n",
    "* ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を最低3つ示す．\n",
    "* 精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指す\n",
    "\n",
    "### ブレンディングとは\n",
    "* N個の多様なモデルを独立して学習させ、推定結果を重み付けした上で足し合わせる方法（＝**加重平均**）\n",
    "* 最も単純には平均をとる\n",
    "* 多様なモデルとは、以下のような条件を変化させることで作り出すものです。\n",
    "* 手法（例：線形回帰、SVM、決定木、ニューラルネットワークなど）\n",
    "* ハイパーパラメータ（例：SVMのカーネルの種類、重みの初期値など）\n",
    "* 入力データの前処理の仕方（例：標準化、対数変換、PCAなど）\n",
    "* 重要なのはそれぞれのモデルが大きく異なること\n",
    "\n",
    "* 回帰問題でのブレンディングは非常に単純であるため、scikit-learnには用意されていない                                    \n",
    "《補足》                                     \n",
    "分類問題の場合は、多数決を行います。回帰問題に比べると複雑なため、scikit-learnにはVotingClassifierが用意されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形回帰，SVM，決定木でやってみる\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### １．重みづけの前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰MSE： 0.477844071097135\n",
      "SVM MSE： 0.38948813290293144\n",
      "決定木MSE： 0.49968449638227497\n",
      "ブレンディングMSE： 0.34587545572714123\n"
     ]
    }
   ],
   "source": [
    "# 線形回帰\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_std,y_train_std)\n",
    "y_pred_lr = lr.predict(X_test_std)\n",
    "print('線形回帰MSE：',mean_squared_error(y_test_std,y_pred_lr))\n",
    "\n",
    "# SVM\n",
    "svm = SVR()\n",
    "svm.fit(X_train_std,y_train_std)\n",
    "y_pred_svm = svm.predict(X_test_std)\n",
    "print('SVM MSE：',mean_squared_error(y_test_std,y_pred_svm))\n",
    "\n",
    "# 決定木\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train_std,y_train_std)\n",
    "y_pred_tree = tree.predict(X_test_std)\n",
    "print('決定木MSE：',mean_squared_error(y_test_std,y_pred_tree))\n",
    "\n",
    "# ブレンディング\n",
    "y_pred_blend = np.array([y_pred_lr,y_pred_svm,y_pred_tree])\n",
    "#print('y_pred_blend_shape',y_pred_blend.shape)\n",
    "y_pred_blend_mean = np.mean(y_pred_blend,axis=0)\n",
    "#print('y_pred_blend_mean_shape',y_pred_blend_mean.shape)\n",
    "print('ブレンディングMSE：',mean_squared_error(y_test_std,y_pred_blend_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ２．SVMの重みを大きくし，決定木の重みを小さくする\n",
    "《メモ》重みづけをした場合は加重平均になる，らしい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰MSE： 0.477844071097135\n",
      "SVM MSE： 0.38948813290293144\n",
      "決定木MSE： 0.49968449638227497\n",
      "ブレンディングMSE： 0.35482720129290596\n"
     ]
    }
   ],
   "source": [
    "print('線形回帰MSE：',mean_squared_error(y_test_std,y_pred_lr))\n",
    "print('SVM MSE：',mean_squared_error(y_test_std,y_pred_svm))\n",
    "print('決定木MSE：',mean_squared_error(y_test_std,y_pred_tree))\n",
    "\n",
    "# 決定木の結果に重み\n",
    "y_pred_blend = np.array([y_pred_lr*0.2,y_pred_svm*0.7,y_pred_tree*0.1])\n",
    "#print('y_pred_blend:\\n',y_pred_blend)\n",
    "#print('y_pred_blend_shape',y_pred_blend.shape)\n",
    "y_pred_blend_mean = np.sum(y_pred_blend,axis=0)\n",
    "print('ブレンディングMSE：',mean_squared_error(y_test_std,y_pred_blend_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ３．SVMのカーネルを変える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1000.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "  gamma='auto_deprecated', kernel='poly', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_rbf.fit(X_train_std,y_train_std)\n",
    "svr_lin = SVR(kernel='linear', C=1e3)\n",
    "svr_lin.fit(X_train_std,y_train_std)\n",
    "svr_poly = SVR(kernel='poly', C=1e3, degree=3)\n",
    "svr_poly.fit(X_train_std,y_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_rbf MSE： 1.511318529011156\n",
      "SVM_linear MSE： 0.476112946512674\n",
      "SVM_poly MSE： 7.448946976672513\n",
      "ブレンディングMSE： 0.38254861157261427\n"
     ]
    }
   ],
   "source": [
    "y_pred_rbf = svr_rbf.predict(X_test_std)\n",
    "print('SVM_rbf MSE：',mean_squared_error(y_test_std,y_pred_rbf))\n",
    "y_pred_lin = svr_lin.predict(X_test_std)\n",
    "print('SVM_linear MSE：',mean_squared_error(y_test_std,y_pred_lin))\n",
    "y_pred_poly = svr_poly.predict(X_test_std)\n",
    "print('SVM_poly MSE：',mean_squared_error(y_test_std,y_pred_poly))\n",
    "\n",
    "# linearの重みを大きく，polyの重みを小さく\n",
    "y_pred_blend = np.array([y_pred_rbf*0.2,y_pred_lin*0.7,y_pred_poly*0.1])\n",
    "#print('y_pred_blend:\\n',y_pred_blend)\n",
    "#print('y_pred_blend_shape',y_pred_blend.shape)\n",
    "y_pred_blend_mean = np.sum(y_pred_blend,axis=0)\n",
    "print('ブレンディングMSE：',mean_squared_error(y_test_std,y_pred_blend_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ４．PCAで次元を削減してブレンディングしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# 対数変換\n",
    "X_train_log = np.log(X_train)\n",
    "X_test_log = np.log(X_test)\n",
    "y_train_log = np.log(y_train)\n",
    "y_test_log = np.log(y_test)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 1)\n",
    "pca = pca.fit(X_train_std)\n",
    "X_train_pca = pca.transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰MSE： 0.47319678982351676\n",
      "SVM MSE： 2.26708340753292\n",
      "決定木MSE： 0.48021830581989333\n",
      "ブレンディングMSE： 0.3380313450753737\n"
     ]
    }
   ],
   "source": [
    "# 線形回帰\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_pca,y_train_std)\n",
    "y_pred_lr = lr.predict(X_test_pca)\n",
    "print('線形回帰MSE：',mean_squared_error(y_test_std,y_pred_lr))\n",
    "\n",
    "# SVM\n",
    "svm = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svm.fit(X_train_pca,y_train_std)\n",
    "y_pred_svm = svm.predict(X_test_pca)\n",
    "print('SVM MSE：',mean_squared_error(y_test_std,y_pred_svm))\n",
    "\n",
    "# 決定木\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train_pca,y_train_std)\n",
    "y_pred_tree = tree.predict(X_test_pca)\n",
    "print('決定木MSE：',mean_squared_error(y_test_std,y_pred_tree))\n",
    "\n",
    "# ブレンディング\n",
    "y_pred_blend = np.array([y_pred_lr*0.5,y_pred_svm*0.1,y_pred_tree*0.4])\n",
    "y_pred_blend_mean = np.sum(y_pred_blend,axis=0)\n",
    "print('ブレンディングMSE：',mean_squared_error(y_test_std,y_pred_blend_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】バギングのスクラッチ実装\n",
    "* バギングをスクラッチ実装し、単一モデルより精度があがる例を最低1つ示す\n",
    "### バギングとは\n",
    "* 入力データの選び方を多様化する方法\n",
    "* 学習データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ ブートストラップサンプル ）を作り出す。\n",
    "* それらによってモデルをN個学習し、推定結果の平均をとる．\n",
    "* ブレンディングと異なり、それぞれの重み付けを変えることはない\n",
    "* scikit-learnのtrain_test_splitを、shuffle=Trueにして使うことで、ランダムにデータを分割することができる．\n",
    "* これによりブートストラップサンプルが手に入ります。\n",
    "* 推定結果の平均をとる部分はブースティングと同様の実装になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習する個数\n",
    "N = 300\n",
    "# 推定結果を入れるarray\n",
    "y_pred_list = np.array([]).reshape(0,len(X_test_std))\n",
    "\n",
    "for i in range(N):\n",
    "    # trainデータとtestデータに分ける\n",
    "    X_train_b,X_test_b,y_train_b,y_test_b = train_test_split(X,y,test_size=0.2,shuffle=True)\n",
    "    #print('{0}回目\\n{1}'.format(i,X_train_))\n",
    "    # 標準化する\n",
    "    sc.fit(X_train_b)\n",
    "    X_train_b_std = sc.transform(X_train_b)\n",
    "    X_test_b_std = sc.transform(X_test_b)\n",
    "    sc.fit(y_train_b[:,np.newaxis])\n",
    "    y_train_b_std = sc.transform(y_train_b[:,np.newaxis]).flatten()\n",
    "    y_test_b_std = sc.transform(y_test_b[:,np.newaxis]).flatten()\n",
    "    \n",
    "    # 学習\n",
    "    tree.fit(X_train_b_std,y_train_b_std)\n",
    "    # 推定は毎回同じデータで行う（外のデータ）\n",
    "    y_pred_b = tree.predict(X_test_std)\n",
    "    y_pred_list = np.vstack((y_pred_list,y_pred_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "バギング MSE: 0.11228871192724019\n",
      "決定木 MSE： 0.5133655975625967\n"
     ]
    }
   ],
   "source": [
    "#print('y_pred_shape',y_pred_list.shape)\n",
    "# 全部の推定結果の平均をとる\n",
    "y_pred_mean = np.mean(y_pred_list,axis=0)\n",
    "#print(y_pred_mean.shape)\n",
    "#print('y_pred_mean:',y_pred_mean)\n",
    "mse = mean_squared_error(y_test_std,y_pred_mean)\n",
    "print('バギング MSE:',mse)\n",
    "\n",
    "# 決定木\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train_std,y_train_std)\n",
    "y_pred_tree = tree.predict(X_test_std)\n",
    "#print(y_pred_tree.shape)\n",
    "print('決定木 MSE：',mean_squared_error(y_test_std,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】スタッキングのスクラッチ実装\n",
    "* スタッキングをスクラッチ実装し、単一モデルより精度があがる例を最低1つ示す．\n",
    "* 最低限ステージ0とステージ1があればスタッキングは成立するため、それを実装する\n",
    "* K=3,M=2程度する\n",
    "\n",
    "## スタッキングの手順\n",
    "### 《学習時》\n",
    "#### （ステージ0）\n",
    "* 学習データをK個に分割する\n",
    "* 分割した内の(K−1)個をまとめて学習用データ、残り1個を推定用データとする組み合わせがK個作れる。\n",
    "* あるモデルのインスタンスをK個用意し、異なる学習用データを使い学習する。\n",
    "* それぞれの学習済みモデルに対して、使っていない残り1個の推定用データを入力し、推定値を得る。（これをブレンドデータと呼ぶ）\n",
    "* さらに、異なるモデルのインスタンスもK個用意し、同様のことを行う。\n",
    "* モデルがM個あれば、M個のブレンドデータが得られる。\n",
    "#### （ステージn ）\n",
    "* ステージn−1のブレンドデータをMn−1次元の特徴量を持つ学習用データと考え、Kn個に分割する。以下同様\n",
    "#### （ステージ N ）最後のステージ\n",
    "* ステージN−1のMN−1個のブレンドデータをMN−1次元の特徴量の入力として、1種類のモデルの学習を行う。\n",
    "* これが最終的な推定を行うモデルとなる。\n",
    "### 《推定時》\n",
    "#### （ステージ 0 ）\n",
    "* テストデータをK0×M0個の学習済みモデルに入力し,K0×M0個の推定値を得る。\n",
    "* これをK0の軸で平均値を求めM0次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "#### （ステージ n ）\n",
    "* ステージn−1で得たブレンドテストをKn×Mn個の学習済みモデルに入力し、Kn×Mn個の推定値を得る。\n",
    "* これをKnの軸で平均値を求めM0次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "#### （ステージN ）＊最後のステージ\n",
    "* ステージN−1で得たブレンドテストを学習済みモデルに入力し、推定値を得る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数\n",
    "K = 4\n",
    "# KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# ラストステージ前までの関数\n",
    "def get_oof(model, X_train, y_train, X_test,K):\n",
    "    kf = KFold(n_splits=K,shuffle=True)\n",
    "    # trainデータのブレンドデータを入れる箱\n",
    "    oof_train = np.zeros((X_train_std.shape[0]))\n",
    "    \n",
    "    # testデータのブレンドデータを入れる箱\n",
    "    oof_test = np.zeros((X_test_std.shape[0]))\n",
    "    oof_test_skf = np.array([]).reshape(0,X_test_std.shape[0])\n",
    "    \n",
    "    # K個のバリデーションデータを作成\n",
    "    for train_index, test_index in kf.split(X_train_std):\n",
    "        X_tr, X_te = X_train_std[train_index], X_train_std[test_index]\n",
    "        y_tr, y_te = y_train_std[train_index], y_train_std[test_index]\n",
    "        \n",
    "        # それぞれのバリデーションデータで学習\n",
    "        model.fit(X_tr, y_tr)\n",
    "        \n",
    "        # それぞれのバリデーションデータで推定（学習フェーズ）\n",
    "        oof_train[test_index] = model.predict(X_te)\n",
    "        #print('oof_train',oof_train[test_index])\n",
    "        # 学習したmodelをtestデータで推定(推定フェーズ)\n",
    "        oof_test_skf = np.vstack((oof_test_skf,model.predict(X_test_std)))\n",
    "        #print('oof_test_skf',oof_test_skf)\n",
    "    # testデータのpredictの平均\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのインスタンス化\n",
    "lr = LinearRegression()                 #線形回帰\n",
    "svm = SVR(kernel='rbf',gamma='scale')  #SVM\n",
    "tree = DecisionTreeRegressor()         #決定木\n",
    "\n",
    "# ラストステージの手前まで学習\n",
    "lr_oof_train,lr_oof_test = get_oof(lr,X_train_std,y_train_std,X_test_std,K)\n",
    "sv_oof_train,sv_oof_test = get_oof(svm,X_train_std,y_train_std,X_test_std,K)\n",
    "tree_oof_train,tree_oof_test = get_oof(tree,X_train_std,y_train_std,X_test_std,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_train： (1168, 3)\n",
      "base_： (1168, 2)\n",
      "meta： (292, 3)\n",
      "base： (292, 2)\n"
     ]
    }
   ],
   "source": [
    "# 各モデルから得たブレンドデータをくっつける\n",
    "meta_train = np.concatenate((lr_oof_train,sv_oof_train,tree_oof_train),axis=1)\n",
    "print('meta_train：',meta_train.shape)\n",
    "print('base_：',X_train_std.shape)\n",
    "\n",
    "# ブレンドテストの結果をくっつける\n",
    "meta_test = np.concatenate((lr_oof_test,sv_oof_test,tree_oof_test),axis=1)\n",
    "print('meta：',meta_test.shape)\n",
    "print('base：',X_test_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラストステージはlightgbmで\n",
    "import lightgbm as lgb\n",
    "# LightGBM用のデータセットを作成する\n",
    "train_set = lgb.Dataset(data=meta_train, label=y_train_std)\n",
    "test_set = lgb.Dataset(data=meta_test,label=y_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.982229\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's l2: 0.869797\n",
      "[3]\tvalid_0's l2: 0.774438\n",
      "[4]\tvalid_0's l2: 0.698588\n",
      "[5]\tvalid_0's l2: 0.637235\n",
      "[6]\tvalid_0's l2: 0.580235\n",
      "[7]\tvalid_0's l2: 0.536522\n",
      "[8]\tvalid_0's l2: 0.500156\n",
      "[9]\tvalid_0's l2: 0.470461\n",
      "[10]\tvalid_0's l2: 0.442445\n",
      "[11]\tvalid_0's l2: 0.420988\n",
      "[12]\tvalid_0's l2: 0.406768\n",
      "[13]\tvalid_0's l2: 0.39171\n",
      "[14]\tvalid_0's l2: 0.382364\n",
      "[15]\tvalid_0's l2: 0.373055\n",
      "[16]\tvalid_0's l2: 0.367625\n",
      "[17]\tvalid_0's l2: 0.361514\n",
      "[18]\tvalid_0's l2: 0.357609\n",
      "[19]\tvalid_0's l2: 0.353598\n",
      "[20]\tvalid_0's l2: 0.350804\n",
      "[21]\tvalid_0's l2: 0.348641\n",
      "[22]\tvalid_0's l2: 0.346279\n",
      "[23]\tvalid_0's l2: 0.343986\n",
      "[24]\tvalid_0's l2: 0.343374\n",
      "[25]\tvalid_0's l2: 0.342125\n",
      "[26]\tvalid_0's l2: 0.340142\n",
      "[27]\tvalid_0's l2: 0.338939\n",
      "[28]\tvalid_0's l2: 0.338087\n",
      "[29]\tvalid_0's l2: 0.338188\n",
      "[30]\tvalid_0's l2: 0.337309\n",
      "[31]\tvalid_0's l2: 0.336664\n",
      "[32]\tvalid_0's l2: 0.33594\n",
      "[33]\tvalid_0's l2: 0.335801\n",
      "[34]\tvalid_0's l2: 0.336608\n",
      "[35]\tvalid_0's l2: 0.337579\n",
      "[36]\tvalid_0's l2: 0.339386\n",
      "[37]\tvalid_0's l2: 0.33908\n",
      "[38]\tvalid_0's l2: 0.340485\n",
      "[39]\tvalid_0's l2: 0.340594\n",
      "[40]\tvalid_0's l2: 0.341305\n",
      "[41]\tvalid_0's l2: 0.341289\n",
      "[42]\tvalid_0's l2: 0.342878\n",
      "[43]\tvalid_0's l2: 0.343943\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's l2: 0.335801\n"
     ]
    }
   ],
   "source": [
    "params = {'task' : 'train',\n",
    "          'boosting_type' : 'gbdt',\n",
    "          'objective' : 'regression',\n",
    "          'metric' : {'l2'},\n",
    "          'num_leaves' : 31,\n",
    "          'learning_rate' : 0.1,\n",
    "          'feature_fraction' : 0.9,\n",
    "          'bagging_fraction' : 0.8,\n",
    "          'bagging_freq': 5,\n",
    "          'verbose' : 1\n",
    "         }\n",
    "gbm = lgb.train(params,train_set,num_boost_round=100,valid_sets=test_set,early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacking MSE： 0.33580073191621307\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(meta_test,num_iteration=gbm.best_iteration)\n",
    "print('stacking MSE：',mean_squared_error(y_test_std,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 1.0476\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's l2: 0.947428\n",
      "[3]\tvalid_0's l2: 0.891787\n",
      "[4]\tvalid_0's l2: 0.816192\n",
      "[5]\tvalid_0's l2: 0.774592\n",
      "[6]\tvalid_0's l2: 0.714668\n",
      "[7]\tvalid_0's l2: 0.682924\n",
      "[8]\tvalid_0's l2: 0.637006\n",
      "[9]\tvalid_0's l2: 0.613492\n",
      "[10]\tvalid_0's l2: 0.578372\n",
      "[11]\tvalid_0's l2: 0.560209\n",
      "[12]\tvalid_0's l2: 0.535967\n",
      "[13]\tvalid_0's l2: 0.522324\n",
      "[14]\tvalid_0's l2: 0.502691\n",
      "[15]\tvalid_0's l2: 0.492492\n",
      "[16]\tvalid_0's l2: 0.477756\n",
      "[17]\tvalid_0's l2: 0.470162\n",
      "[18]\tvalid_0's l2: 0.459011\n",
      "[19]\tvalid_0's l2: 0.453265\n",
      "[20]\tvalid_0's l2: 0.444317\n",
      "[21]\tvalid_0's l2: 0.441111\n",
      "[22]\tvalid_0's l2: 0.4348\n",
      "[23]\tvalid_0's l2: 0.432545\n",
      "[24]\tvalid_0's l2: 0.427587\n",
      "[25]\tvalid_0's l2: 0.425999\n",
      "[26]\tvalid_0's l2: 0.421023\n",
      "[27]\tvalid_0's l2: 0.41943\n",
      "[28]\tvalid_0's l2: 0.414911\n",
      "[29]\tvalid_0's l2: 0.413886\n",
      "[30]\tvalid_0's l2: 0.411071\n",
      "[31]\tvalid_0's l2: 0.410563\n",
      "[32]\tvalid_0's l2: 0.407865\n",
      "[33]\tvalid_0's l2: 0.407587\n",
      "[34]\tvalid_0's l2: 0.405621\n",
      "[35]\tvalid_0's l2: 0.405544\n",
      "[36]\tvalid_0's l2: 0.402724\n",
      "[37]\tvalid_0's l2: 0.402231\n",
      "[38]\tvalid_0's l2: 0.401174\n",
      "[39]\tvalid_0's l2: 0.400382\n",
      "[40]\tvalid_0's l2: 0.399134\n",
      "[41]\tvalid_0's l2: 0.397865\n",
      "[42]\tvalid_0's l2: 0.39691\n",
      "[43]\tvalid_0's l2: 0.395897\n",
      "[44]\tvalid_0's l2: 0.39519\n",
      "[45]\tvalid_0's l2: 0.394373\n",
      "[46]\tvalid_0's l2: 0.393867\n",
      "[47]\tvalid_0's l2: 0.394029\n",
      "[48]\tvalid_0's l2: 0.393435\n",
      "[49]\tvalid_0's l2: 0.393618\n",
      "[50]\tvalid_0's l2: 0.392905\n",
      "[51]\tvalid_0's l2: 0.393143\n",
      "[52]\tvalid_0's l2: 0.393471\n",
      "[53]\tvalid_0's l2: 0.393767\n",
      "[54]\tvalid_0's l2: 0.394196\n",
      "[55]\tvalid_0's l2: 0.394544\n",
      "[56]\tvalid_0's l2: 0.393747\n",
      "[57]\tvalid_0's l2: 0.393579\n",
      "[58]\tvalid_0's l2: 0.393075\n",
      "[59]\tvalid_0's l2: 0.392993\n",
      "[60]\tvalid_0's l2: 0.393217\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's l2: 0.392905\n",
      "single MSE： 0.4075866479867016\n"
     ]
    }
   ],
   "source": [
    "# LightGBM用のデータセットを作成する\n",
    "train_single = lgb.Dataset(data=X_train_std, label=y_train_std)\n",
    "test_single = lgb.Dataset(data=X_test_std,label=y_test_std)\n",
    "\n",
    "gbm_single = lgb.train(params,train_single,num_boost_round=100,valid_sets=test_single,early_stopping_rounds=10)\n",
    "y_pred_single = gbm_single.predict(X_test_std,num_iteration=gbm.best_iteration)\n",
    "print('single MSE：',mean_squared_error(y_test_std,y_pred_single))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ラストステージをSVMにしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM MSE： 0.3894881329029319\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm = SVR(kernel='rbf',gamma='scale')\n",
    "svm.fit(X_train_std,y_train_std)\n",
    "y_pred_svm = svm.predict(X_test_std)\n",
    "print('SVM MSE：',mean_squared_error(y_test_std,y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacking MSE: 0.40658546211700314\n"
     ]
    }
   ],
   "source": [
    "svm_ensemble = SVR(kernel='rbf',gamma='scale')\n",
    "svm_ensemble.fit(meta_train,y_train_std)\n",
    "y_pred_ensemble = svm_ensemble.predict(meta_test)\n",
    "print('stacking MSE:',mean_squared_error(y_test_std,y_pred_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# クラスにしたい．．．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
