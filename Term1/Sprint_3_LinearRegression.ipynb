{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint３ 機械学習スクラッチ 線形回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# データの読み込み\n",
    "df = pd.read_csv('C:/Users/miyas/kaggle/train.csv')\n",
    "X = df.loc[:,['GrLivArea','YearBuilt']].values\n",
    "y = df.SalePrice.values\n",
    "\n",
    "# データの前処理\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)\n",
    "# 標準化\n",
    "X_train_std = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_std = (X_test -X_test.mean()) / X_test.std()\n",
    "y_train_std = (y_train - y_train.mean()) / y_train.std()\n",
    "y_test_std = (y_test - y_test.mean()) / y_test.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数の動きを確認するために，仮データを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_1_shape : (365, 3)\n",
      "coef_shape： 　 (3,)\n"
     ]
    }
   ],
   "source": [
    "# バイアス項の追加\n",
    "X_1 = np.insert(X_test_std, 0, 1, axis=1)\n",
    "# シータの初期値\n",
    "coef = np.random.rand(X_1.shape[1])\n",
    "# パラメータ\n",
    "lr = 0.001\n",
    "\n",
    "# shapeの確認\n",
    "print('X_1_shape :',X_1.shape)\n",
    "print('coef_shape： 　',coef.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】仮定関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _linear_hypothesis(X,coef):\n",
    "    \"\"\"\n",
    "    線形の仮定関数を計算する\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_samples, 1)\n",
    "      線形の仮定関数による推定結果\n",
    "\n",
    "    \"\"\"\n",
    "    hypothesis = np.dot(X,coef)\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 仮のデータで確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothesis_shape： (365,) \n",
      "\n",
      "[0.97850462 0.73399035 0.6472075  0.87028689 0.63470336 0.57343699\n",
      " 0.75309517 0.68063294 1.49420104 0.66091712 0.72452435 0.78452039\n",
      " 0.87640649 0.58408139 0.6156796  0.67984364 0.85645287 0.62587531\n",
      " 0.66492842 0.77696823 0.6939047  0.59775319 0.56031653 0.74797568\n",
      " 0.83182306 0.73235237 0.77516795 0.51909563 0.81128557 0.6482833\n",
      " 0.79545137 0.82036769 0.59497452 0.93059103 0.89854413 0.74070999\n",
      " 0.77577883 0.58320021 0.90688563 1.03171604 0.88469396 0.68984478\n",
      " 0.71336092 0.84344598 1.07520747 0.78782888 0.55680263 0.58906033\n",
      " 0.78670442 0.57644271 1.04962618 0.6256645  0.69919717 0.53753558\n",
      " 0.78491502 0.57999444 0.67539452 0.83546129 0.63616299 0.54281726\n",
      " 0.61950164 0.61297658 0.66044684 0.64459098 0.79721371 0.72062665\n",
      " 0.58313535 0.8112315  0.63013533 0.81711326 0.74298051 0.60796521\n",
      " 0.58423818 0.74190471 0.59109301 0.79763537 0.60510541 0.56618209\n",
      " 0.99983673 0.68189252 0.60238076 0.58303802 0.65425699 0.62587531\n",
      " 1.11259014 0.7186372  0.62477796 0.72778418 0.69186658 0.62237224\n",
      " 0.80083574 0.75816063 0.75292218 0.8482249  0.70114872 0.66683135\n",
      " 0.75591171 0.74132634 0.57728602 0.72483797 0.81879994 0.8641132\n",
      " 0.68630924 0.72207545 0.51127856 0.97858027 0.71766412 0.57447492\n",
      " 0.75663071 0.6591224  0.49402796 0.61184672 0.85876126 0.61816097\n",
      " 0.74435905 0.75169503 0.98099135 0.61602016 0.89365712 0.87547124\n",
      " 0.65544623 0.73519043 0.60165096 0.85287411 0.77817911 0.75801464\n",
      " 0.9157569  0.71184183 0.69692122 0.74547811 0.71606394 0.69667254\n",
      " 0.92593646 0.72843293 0.57728602 0.80033838 0.7111391  0.71946432\n",
      " 0.57498307 0.77687626 0.63452498 0.65417582 0.91196733 0.62608616\n",
      " 0.67454573 0.75223022 0.75359252 0.61637696 0.82327612 0.75408448\n",
      " 0.71247978 0.81299927 0.83665061 0.8591884  0.74436992 1.0604977\n",
      " 0.61995577 0.71019306 0.66755031 0.74678635 0.57800502 0.64994835\n",
      " 0.78022798 0.60115901 0.77973063 0.70300306 0.72145918 0.96402186\n",
      " 0.72457841 0.80426315 0.70034867 0.75854986 0.71236622 0.65739782\n",
      " 0.59661797 0.63893087 0.63723879 1.01534663 0.65512194 0.64034724\n",
      " 0.90195535 0.83845085 0.60449997 0.81277763 0.55497    0.79443503\n",
      " 0.60787329 0.691699   0.7369582  0.59775319 0.62587531 0.69197475\n",
      " 0.76859423 0.60841387 0.62919468 0.62191811 0.51909563 0.6367955\n",
      " 0.78340676 0.70259216 0.68677956 0.68074642 0.53432982 0.62680516\n",
      " 0.80305227 1.01672517 0.66920999 0.91940056 0.82910381 0.53702204\n",
      " 0.66390125 0.79481343 0.60667317 0.52431788 0.82840105 0.95068523\n",
      " 0.7183453  1.05282115 0.80012214 0.52053363 0.73567159 0.70714944\n",
      " 0.72587594 0.57872402 0.7621016  0.89494913 0.86543767 0.82905519\n",
      " 0.66332284 0.70743054 0.60595417 0.62023148 0.57800502 0.6537001\n",
      " 0.83973746 0.69127198 0.8109342  0.55807304 0.63811998 0.72278365\n",
      " 0.66519333 0.799814   0.82708737 0.82885514 0.68057344 0.64449365\n",
      " 0.71069577 0.78028204 0.66612858 0.73913683 0.71059848 0.8704977\n",
      " 0.54277403 1.12066668 0.71723163 0.84344598 0.55980838 0.77920624\n",
      " 1.20156777 1.79278632 0.81572932 0.71636132 0.79730024 0.63388711\n",
      " 0.90727486 0.8296336  1.03628955 0.46082417 0.84951159 0.81100986\n",
      " 0.6961266  0.84804116 0.71511793 0.76330176 0.87502803 0.90511786\n",
      " 0.81105312 0.77355701 0.8712978  0.65871154 0.58618433 0.87925546\n",
      " 0.71382049 0.73189281 0.71010109 0.87994207 0.66675565 0.80644178\n",
      " 0.98707311 0.95176107 0.51692243 0.60275923 0.84361356 0.57899433\n",
      " 0.56692273 0.80545247 0.76792929 0.69050968 0.68808241 0.73540668\n",
      " 0.61027896 0.64446666 0.79796514 0.72629212 0.81687002 0.69285593\n",
      " 0.62562667 0.72428651 0.75110575 0.67944897 0.60667317 0.69485071\n",
      " 0.77554103 0.65204053 0.67762178 0.59775319 0.94866335 0.65215401\n",
      " 0.73850432 0.83609927 0.62439412 0.79655417 0.57814022 1.09290143\n",
      " 0.76270175 0.86441593 0.60398095 0.84538133 0.75875531 0.64000127\n",
      " 0.59939124 0.85418775 0.73522294 0.71629098 0.72102128 0.63122188\n",
      " 0.63447632 0.73830971 0.69058541 0.61526873 0.8317852  0.68495229\n",
      " 0.76464791 0.87403324 0.66786388 0.73278479 0.61489034 0.60866258\n",
      " 0.55974892 0.6034025  0.82725495 1.02959147 0.58059452 0.57169621\n",
      " 0.7150422  0.90456644 1.00980544 0.77836296 0.79241315 0.88696448\n",
      " 0.99714463 0.83702365 0.76323146 0.7797036  0.51723601]\n"
     ]
    }
   ],
   "source": [
    "hypothesis = _linear_hypothesis(X_1,coef)\n",
    "print('hypothesis_shape：',hypothesis.shape,'\\n')\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】最急降下法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gradient_descent(X,error,lr,coef):\n",
    "    \"\"\"\n",
    "    最急降下法によるパラメータの更新．\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "    データの特徴量\n",
    "    error : 次の形のndarray, shape (n_samples,)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "      次の形のndarray, shape (n_features,)\n",
    "      線形回帰式の切片と重み\n",
    "\n",
    "    \"\"\"\n",
    "    coef = coef - lr/len(X) * np.dot(error,X)\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 仮データで確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_shape： (365,)\n"
     ]
    }
   ],
   "source": [
    "# 予測値と実測値の差\n",
    "error = (_linear_hypothesis(X_1,coef)) - y_test_std\n",
    "print('error_shape：',error.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62437304 0.11447922 0.3276985 ]\n",
      "[0.62363653 0.11549743 0.32734707]\n",
      "[0.62290002 0.11651564 0.32699565]\n",
      "[0.62216352 0.11753385 0.32664422]\n",
      "[0.62142701 0.11855206 0.32629279]\n",
      "[0.6206905  0.11957027 0.32594136]\n",
      "[0.61995399 0.12058848 0.32558993]\n",
      "[0.61921749 0.12160669 0.3252385 ]\n",
      "[0.61848098 0.1226249  0.32488707]\n",
      "[0.61774447 0.12364311 0.32453564]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    coef =_gradient_descent(X_1,error,lr,coef)\n",
    "    print(coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,coef):\n",
    "    \"\"\"\n",
    "    線形回帰を使い推定する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        サンプル\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "        線形回帰による推定結果\n",
    "    \"\"\"\n",
    "    y_pred = np.dot(X,coef).reshape(-1,1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 仮データで確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_shape： (365, 1)\n",
      "y_test_shape： (365,)\n",
      "\n",
      "predict：\n",
      " [[0.98683359]\n",
      " [0.721532  ]\n",
      " [0.62631115]\n",
      " [0.86745979]\n",
      " [0.61116813]\n",
      " [0.54880944]\n",
      " [0.73758438]\n",
      " [0.66367515]\n",
      " [1.54599228]\n",
      " [0.63735087]\n",
      " [0.70652182]\n",
      " [0.77406874]\n",
      " [0.87253959]\n",
      " [0.5562922 ]\n",
      " [0.59209835]\n",
      " [0.6613705 ]\n",
      " [0.8513009 ]\n",
      " [0.59988664]\n",
      " [0.64446674]\n",
      " [0.77024464]\n",
      " [0.67705455]\n",
      " [0.56851855]\n",
      " [0.53068356]\n",
      " [0.7329444 ]\n",
      " [0.82576086]\n",
      " [0.72400838]\n",
      " [0.76214358]\n",
      " [0.48525787]\n",
      " [0.80099684]\n",
      " [0.62770017]\n",
      " [0.78728076]\n",
      " [0.81190517]\n",
      " [0.56736839]\n",
      " [0.93151447]\n",
      " [0.89601385]\n",
      " [0.72488223]\n",
      " [0.76244815]\n",
      " [0.55497081]\n",
      " [0.90546504]\n",
      " [1.04214789]\n",
      " [0.88510986]\n",
      " [0.6724136 ]\n",
      " [0.6944288 ]\n",
      " [0.83626004]\n",
      " [1.08947006]\n",
      " [0.77854086]\n",
      " [0.52743212]\n",
      " [0.56106792]\n",
      " [0.77630432]\n",
      " [0.54948476]\n",
      " [1.06101527]\n",
      " [0.60175147]\n",
      " [0.68101632]\n",
      " [0.5074472 ]\n",
      " [0.77355984]\n",
      " [0.55154957]\n",
      " [0.65991674]\n",
      " [0.82748657]\n",
      " [0.61333655]\n",
      " [0.51269728]\n",
      " [0.59518   ]\n",
      " [0.58857495]\n",
      " [0.64023301]\n",
      " [0.62244865]\n",
      " [0.7866011 ]\n",
      " [0.70581342]\n",
      " [0.55605574]\n",
      " [0.80079348]\n",
      " [0.61059594]\n",
      " [0.80763642]\n",
      " [0.7267787 ]\n",
      " [0.58434171]\n",
      " [0.55754645]\n",
      " [0.72538968]\n",
      " [0.56472753]\n",
      " [0.78619389]\n",
      " [0.57956406]\n",
      " [0.53945897]\n",
      " [1.00661322]\n",
      " [0.66309766]\n",
      " [0.57529483]\n",
      " [0.55436071]\n",
      " [0.6368823 ]\n",
      " [0.59988664]\n",
      " [1.13374656]\n",
      " [0.70032303]\n",
      " [0.60439667]\n",
      " [0.71014642]\n",
      " [0.67071664]\n",
      " [0.59866934]\n",
      " [0.79025927]\n",
      " [0.74534344]\n",
      " [0.73826259]\n",
      " [0.84161228]\n",
      " [0.68104844]\n",
      " [0.64697379]\n",
      " [0.74087036]\n",
      " [0.73118753]\n",
      " [0.54867033]\n",
      " [0.71235276]\n",
      " [0.80933001]\n",
      " [0.85885418]\n",
      " [0.66841633]\n",
      " [0.70594771]\n",
      " [0.47977279]\n",
      " [0.98446035]\n",
      " [0.69998489]\n",
      " [0.54806264]\n",
      " [0.74158166]\n",
      " [0.64189544]\n",
      " [0.4620575 ]\n",
      " [0.58698257]\n",
      " [0.85533319]\n",
      " [0.59545244]\n",
      " [0.72864208]\n",
      " [0.73829761]\n",
      " [0.98622108]\n",
      " [0.59138609]\n",
      " [0.89357732]\n",
      " [0.87101483]\n",
      " [0.63138902]\n",
      " [0.71807286]\n",
      " [0.57587184]\n",
      " [0.8491344 ]\n",
      " [0.76549719]\n",
      " [0.74280089]\n",
      " [0.91491576]\n",
      " [0.69270116]\n",
      " [0.67644155]\n",
      " [0.73152277]\n",
      " [0.6979522 ]\n",
      " [0.67617056]\n",
      " [0.92795895]\n",
      " [0.71258681]\n",
      " [0.54867033]\n",
      " [0.78971728]\n",
      " [0.69670229]\n",
      " [0.70144106]\n",
      " [0.54731633]\n",
      " [0.76458301]\n",
      " [0.61249048]\n",
      " [0.62993237]\n",
      " [0.91461409]\n",
      " [0.60134425]\n",
      " [0.65473044]\n",
      " [0.73765298]\n",
      " [0.73812637]\n",
      " [0.59206381]\n",
      " [0.81420789]\n",
      " [0.73931251]\n",
      " [0.69642985]\n",
      " [0.80279211]\n",
      " [0.82863817]\n",
      " [0.86092671]\n",
      " [0.73399867]\n",
      " [1.07466807]\n",
      " [0.59755276]\n",
      " [0.69646584]\n",
      " [0.64436265]\n",
      " [0.7317928 ]\n",
      " [0.54938163]\n",
      " [0.62864792]\n",
      " [0.76722435]\n",
      " [0.5746857 ]\n",
      " [0.76668236]\n",
      " [0.68935286]\n",
      " [0.7062873 ]\n",
      " [0.96823432]\n",
      " [0.70672519]\n",
      " [0.79384981]\n",
      " [0.68335454]\n",
      " [0.74547869]\n",
      " [0.69334483]\n",
      " [0.63474359]\n",
      " [0.57089275]\n",
      " [0.61577501]\n",
      " [0.61472558]\n",
      " [1.025754  ]\n",
      " [0.63681371]\n",
      " [0.61645177]\n",
      " [0.90153685]\n",
      " [0.83341678]\n",
      " [0.58193779]\n",
      " [0.8026228 ]\n",
      " [0.52651843]\n",
      " [0.78545095]\n",
      " [0.58200252]\n",
      " [0.67075069]\n",
      " [0.72007149]\n",
      " [0.56851855]\n",
      " [0.59988664]\n",
      " [0.67444581]\n",
      " [0.75469102]\n",
      " [0.58071373]\n",
      " [0.60971534]\n",
      " [0.59629658]\n",
      " [0.48525787]\n",
      " [0.61438696]\n",
      " [0.77386634]\n",
      " [0.68514933]\n",
      " [0.66885663]\n",
      " [0.66011529]\n",
      " [0.50402597]\n",
      " [0.60205555]\n",
      " [0.79859726]\n",
      " [1.02761738]\n",
      " [0.649277  ]\n",
      " [0.91931976]\n",
      " [0.82084747]\n",
      " [0.50883767]\n",
      " [0.64060279]\n",
      " [0.78355206]\n",
      " [0.58213922]\n",
      " [0.49427118]\n",
      " [0.82152616]\n",
      " [0.95593986]\n",
      " [0.70188281]\n",
      " [1.0657248 ]\n",
      " [0.78890382]\n",
      " [0.48668046]\n",
      " [0.7205473 ]\n",
      " [0.69033226]\n",
      " [0.71492841]\n",
      " [0.55009292]\n",
      " [0.74754351]\n",
      " [0.89245736]\n",
      " [0.86051419]\n",
      " [0.8233224 ]\n",
      " [0.6430782 ]\n",
      " [0.69006078]\n",
      " [0.58142792]\n",
      " [0.59792543]\n",
      " [0.54938163]\n",
      " [0.63013622]\n",
      " [0.83294097]\n",
      " [0.6751245 ]\n",
      " [0.80299741]\n",
      " [0.52888877]\n",
      " [0.61604697]\n",
      " [0.70794731]\n",
      " [0.64612772]\n",
      " [0.78907361]\n",
      " [0.81857784]\n",
      " [0.82057648]\n",
      " [0.66079349]\n",
      " [0.62075361]\n",
      " [0.69304123]\n",
      " [0.76742771]\n",
      " [0.64765248]\n",
      " [0.72295122]\n",
      " [0.69466863]\n",
      " [0.86559496]\n",
      " [0.51452805]\n",
      " [1.13821433]\n",
      " [0.69835796]\n",
      " [0.83626004]\n",
      " [0.53142988]\n",
      " [0.76603869]\n",
      " [1.22659224]\n",
      " [1.87050617]\n",
      " [0.80641719]\n",
      " [0.70239315]\n",
      " [0.78958444]\n",
      " [0.61540668]\n",
      " [0.9056003 ]\n",
      " [0.82084699]\n",
      " [1.04872081]\n",
      " [0.42486281]\n",
      " [0.84778136]\n",
      " [0.80062417]\n",
      " [0.68142594]\n",
      " [0.84690124]\n",
      " [0.70103819]\n",
      " [0.75072925]\n",
      " [0.87732109]\n",
      " [0.90346641]\n",
      " [0.80211584]\n",
      " [0.76472164]\n",
      " [0.8666113 ]\n",
      " [0.64101435]\n",
      " [0.55822273]\n",
      " [0.87528309]\n",
      " [0.69947985]\n",
      " [0.71895732]\n",
      " [0.6908042 ]\n",
      " [0.8798593 ]\n",
      " [0.64602459]\n",
      " [0.79672954]\n",
      " [0.9924875 ]\n",
      " [0.96065133]\n",
      " [0.48505643]\n",
      " [0.58004083]\n",
      " [0.83622599]\n",
      " [0.55110975]\n",
      " [0.5409161 ]\n",
      " [0.79500141]\n",
      " [0.75418309]\n",
      " [0.66959909]\n",
      " [0.66977081]\n",
      " [0.71888632]\n",
      " [0.5844074 ]\n",
      " [0.62397437]\n",
      " [0.78676993]\n",
      " [0.70852046]\n",
      " [0.81004372]\n",
      " [0.67576721]\n",
      " [0.60293809]\n",
      " [0.70828497]\n",
      " [0.73541644]\n",
      " [0.65855695]\n",
      " [0.58213922]\n",
      " [0.67396856]\n",
      " [0.76753374]\n",
      " [0.6351892 ]\n",
      " [0.66032155]\n",
      " [0.56851855]\n",
      " [0.95099194]\n",
      " [0.63162933]\n",
      " [0.72190082]\n",
      " [0.8345377 ]\n",
      " [0.60361726]\n",
      " [0.78544902]\n",
      " [0.55321248]\n",
      " [1.11416885]\n",
      " [0.75578127]\n",
      " [0.85932854]\n",
      " [0.57732752]\n",
      " [0.83822462]\n",
      " [0.74758046]\n",
      " [0.61780819]\n",
      " [0.57268706]\n",
      " [0.84876028]\n",
      " [0.72417527]\n",
      " [0.69747736]\n",
      " [0.70530452]\n",
      " [0.60737422]\n",
      " [0.61164297]\n",
      " [0.72183319]\n",
      " [0.67387073]\n",
      " [0.59121726]\n",
      " [0.82362503]\n",
      " [0.66397634]\n",
      " [0.75645755]\n",
      " [0.86959223]\n",
      " [0.64687115]\n",
      " [0.71899041]\n",
      " [0.59311614]\n",
      " [0.58430717]\n",
      " [0.53187067]\n",
      " [0.57648049]\n",
      " [0.81854379]\n",
      " [1.03947153]\n",
      " [0.55314244]\n",
      " [0.54359005]\n",
      " [0.69676654]\n",
      " [0.90272106]\n",
      " [1.01819879]\n",
      " [0.77017556]\n",
      " [0.78050303]\n",
      " [0.88700633]\n",
      " [1.01176885]\n",
      " [0.83070588]\n",
      " [0.7491359 ]\n",
      " [0.76658068]\n",
      " [0.48756493]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_1,coef)\n",
    "print('y_pred_shape：',y_pred.shape)\n",
    "print('y_test_shape：',y_test_std.shape)\n",
    "print('\\npredict：\\n',y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】平均二乗誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    平均二乗誤差の計算\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : 次の形のndarray, shape (n_samples,)\n",
    "      推定した値\n",
    "    y : 次の形のndarray, shape (n_samples,)\n",
    "      正解値\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      平均二乗誤差\n",
    "    \"\"\"\n",
    "    mse = np.mean((y_pred - y)**2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5454293655236604"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 仮データで確認\n",
    "MSE(y_pred,y_train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】目的関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7727146827618302"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y_pred,y_test_std)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】学習と推定\n",
    "## １．スクラッチLinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    線形回帰のスクラッチ実装\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      学習用データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証用データに対する損失の記録\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "\n",
    "        \n",
    "    def _linear_hypothesis(self,X,coef):\n",
    "        \"\"\"\n",
    "        線形の仮定関数を計算する\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "          学習データ\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "          次の形のndarray, shape (n_samples, 1)\n",
    "          線形の仮定関数による推定結果\n",
    "\n",
    "        \"\"\"\n",
    "        hypothesis = np.dot(X,coef)\n",
    "        return hypothesis\n",
    "    \n",
    "    \n",
    "    def _gradient_descent(self,X,coef,error):\n",
    "        \"\"\"\n",
    "        最急降下法によるパラメータの更新．\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        データの特徴量\n",
    "        error : 次の形のndarray, shape (n_samples,)\n",
    "        \"\"\"\n",
    "        coef = coef - self.lr/len(X) * np.dot(error,X)\n",
    "        return coef\n",
    "    \n",
    "    \n",
    "    def MSE(self,y_pred, y):\n",
    "        \"\"\"\n",
    "        平均二乗誤差の計算\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : 次の形のndarray, shape (n_samples,)\n",
    "          推定した値\n",
    "        y : 次の形のndarray, shape (n_samples,)\n",
    "          正解値\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        mse : numpy.float\n",
    "          平均二乗誤差\n",
    "        \"\"\"\n",
    "        mse = np.mean((y_pred - y)**2)\n",
    "        return mse\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        線形回帰を学習する。検証用データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        # trainデータ\n",
    "        #バイアス項を入れる場合はXの０列目に１を挿入する\n",
    "        if self.bias is False:\n",
    "            X_new = np.insert(X, 0, 1, axis=1)\n",
    "        #バイアス項を入れない場合はXの０列目に０を挿入する\n",
    "        else:\n",
    "            X_new = np.insert(X, 0, 0, axis=1)\n",
    "\n",
    "        # シータの初期化\n",
    "        self.coef_ = np.random.rand(X_new.shape[1])\n",
    "        # num_iter回更新\n",
    "        for i in range(self.iter):\n",
    "            # 仮定関数\n",
    "            hypothesis = self._linear_hypothesis(X_new,self.coef_)\n",
    "            \n",
    "            # 予測と実測値との誤差\n",
    "            error = hypothesis - y\n",
    "            \n",
    "            # 最急降下法\n",
    "            self.coef_ = self._gradient_descent(X_new,self.coef_,error)\n",
    "            \n",
    "            # lossを記録\n",
    "            self.loss[i] = self.MSE(self._linear_hypothesis(X_new,self.coef_),y)/2\n",
    "        \n",
    "            # 学習過程の出力\n",
    "            if self.verbose is True:\n",
    "                map_result = map(str, self.loss)\n",
    "                result = ',\\n'.join(map_result)                \n",
    "                print('Train Data Loss Iteration{0}: \\n{1}'.format(self.iter,result))\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        \n",
    "        \n",
    "        # 検証用データがある場合\n",
    "        if X_val is not None:\n",
    "            #バイアス項を入れる場合はXの０列目に１を挿入する\n",
    "            if self.bias is False:\n",
    "                X_val_new = np.insert(X_val, 0, 1, axis=1)\n",
    "            #バイアス項を入れない場合、0を挿入する\n",
    "            else:\n",
    "                X_val_new = np.insert(X_val, 0, 0, axis=1)\n",
    "                \n",
    "        # シータの初期化\n",
    "        self.coef_val_ = np.random.rand(X_val_new.shape[1])\n",
    "        # num_iter回更新\n",
    "        for i in range(self.iter):\n",
    "            # 仮定関数\n",
    "            hypothesis_val = self._linear_hypothesis(X_val_new,self.coef_val_)\n",
    "            \n",
    "            # 予測と実測値との誤差\n",
    "            error_val = hypothesis_val - y_val\n",
    "            \n",
    "            # 最急降下法\n",
    "            self.coef_val_ = self._gradient_descent(X_val_new,self.coef_val_,error_val)\n",
    "            \n",
    "            # lossを記録\n",
    "            self.val_loss[i] = self.MSE(self._linear_hypothesis(X_val_new,self.coef_val_),y_val)/2\n",
    "        \n",
    "            # 学習過程の出力\n",
    "            if self.verbose is True:\n",
    "                map_result_val = map(str, self.val_loss)\n",
    "                result_val = ',\\n'.join(map_result_val)                \n",
    "                print('\\nTest Data Loss Iteration{0}: \\n{1}'.format(self.iter,result_val))\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            \n",
    "    def predict(self,X):\n",
    "        \"\"\"\n",
    "        線形回帰を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "        サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "        線形回帰による推定結果\n",
    "        \"\"\"\n",
    "        #バイアス項を入れる場合はXの０列目に１を挿入する\n",
    "        if self.bias is False:\n",
    "            X_add = np.insert(X, 0, 1, axis=1)\n",
    "        #バイアス項を入れない場合、0を挿入する\n",
    "        else:\n",
    "            X_add = np.insert(X, 0, 0, axis=1)\n",
    "            \n",
    "        y_pred = np.dot(X_add,self.coef_).reshape(-1,1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期化，学習\n",
    "slr=ScratchLinearRegression(num_iter=5000, lr=0.001, bias=False ,verbose=False)\n",
    "slr.fit(X=X_train_std, y=y_train_std, X_val=X_test_std, y_val=y_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred:\n",
      " [[ 1.36206468e+00]\n",
      " [ 1.09764926e-01]\n",
      " [-3.85372900e-01]\n",
      " [ 7.14331295e-01]\n",
      " [-5.24732610e-01]\n",
      " [-6.41774616e-01]\n",
      " [-1.59113396e-02]\n",
      " [-1.61753979e-01]\n",
      " [ 3.98510528e+00]\n",
      " [-4.98474609e-01]\n",
      " [-1.65240890e-01]\n",
      " [ 2.59149346e-01]\n",
      " [ 6.71109414e-01]\n",
      " [-7.81623791e-01]\n",
      " [-5.47063316e-01]\n",
      " [-2.35016766e-01]\n",
      " [ 5.88572725e-01]\n",
      " [-6.51338723e-01]\n",
      " [-3.45844403e-01]\n",
      " [ 4.29342636e-01]\n",
      " [-1.42565107e-01]\n",
      " [-8.36242041e-01]\n",
      " [-8.94897324e-01]\n",
      " [ 1.58965981e-03]\n",
      " [ 5.19003323e-01]\n",
      " [ 3.04679950e-01]\n",
      " [ 1.26286996e-01]\n",
      " [-1.13948972e+00]\n",
      " [ 2.95260232e-01]\n",
      " [-3.69263778e-01]\n",
      " [ 3.79740348e-01]\n",
      " [ 3.92156085e-01]\n",
      " [-7.61346251e-01]\n",
      " [ 9.57407647e-01]\n",
      " [ 7.58420940e-01]\n",
      " [-4.41676378e-02]\n",
      " [ 1.12293127e-01]\n",
      " [-8.03596419e-01]\n",
      " [ 8.20287359e-01]\n",
      " [ 1.51888352e+00]\n",
      " [ 8.84579455e-01]\n",
      " [-1.74631745e-01]\n",
      " [-2.21484927e-01]\n",
      " [ 4.77593484e-01]\n",
      " [ 1.74800065e+00]\n",
      " [ 3.18266659e-01]\n",
      " [-8.86071022e-01]\n",
      " [-7.86067985e-01]\n",
      " [ 2.63924184e-01]\n",
      " [-7.49977318e-01]\n",
      " [ 1.58358856e+00]\n",
      " [-5.52355054e-01]\n",
      " [-2.00566317e-01]\n",
      " [-9.40771576e-01]\n",
      " [ 2.16382278e-01]\n",
      " [-8.17287079e-01]\n",
      " [-9.65594695e-02]\n",
      " [ 4.31443457e-01]\n",
      " [-4.89310447e-01]\n",
      " [-9.36692678e-01]\n",
      " [-5.78406580e-01]\n",
      " [-5.89134445e-01]\n",
      " [-3.38740623e-01]\n",
      " [-4.47694133e-01]\n",
      " [ 2.64888682e-01]\n",
      " [-1.69307074e-02]\n",
      " [-7.48709610e-01]\n",
      " [ 2.88066933e-01]\n",
      " [-3.38581803e-01]\n",
      " [ 3.40232071e-01]\n",
      " [-5.96429051e-02]\n",
      " [-5.57246846e-01]\n",
      " [-7.29003839e-01]\n",
      " [-7.57520264e-02]\n",
      " [-7.06156232e-01]\n",
      " [ 2.25718265e-01]\n",
      " [-6.51937927e-01]\n",
      " [-7.49612023e-01]\n",
      " [ 1.31043666e+00]\n",
      " [-2.48225177e-01]\n",
      " [-7.28645759e-01]\n",
      " [-8.25176317e-01]\n",
      " [-2.09591878e-01]\n",
      " [-6.51338723e-01]\n",
      " [ 2.11705648e+00]\n",
      " [-1.86365973e-01]\n",
      " [-3.84490705e-01]\n",
      " [-1.44356930e-01]\n",
      " [-3.50233727e-01]\n",
      " [-5.45795608e-01]\n",
      " [ 2.70448979e-01]\n",
      " [ 1.18191283e-01]\n",
      " [ 2.45888709e-02]\n",
      " [ 5.10052851e-01]\n",
      " [-2.90241435e-01]\n",
      " [-3.14955953e-01]\n",
      " [ 9.50633302e-03]\n",
      " [ 2.28392282e-01]\n",
      " [-8.28318152e-01]\n",
      " [ 9.87959375e-02]\n",
      " [ 3.42347323e-01]\n",
      " [ 5.91562956e-01]\n",
      " [-2.00442147e-01]\n",
      " [-7.82253574e-02]\n",
      " [-1.03630299e+00]\n",
      " [ 1.24509776e+00]\n",
      " [-1.57048442e-01]\n",
      " [-7.25978958e-01]\n",
      " [ 9.89906243e-03]\n",
      " [-1.97382616e-01]\n",
      " [-1.07676855e+00]\n",
      " [-6.12436865e-01]\n",
      " [ 6.73410921e-01]\n",
      " [-5.02725332e-01]\n",
      " [-3.50106913e-02]\n",
      " [ 8.36166642e-02]\n",
      " [ 1.21656569e+00]\n",
      " [-5.97023683e-01]\n",
      " [ 8.70371895e-01]\n",
      " [ 6.41943486e-01]\n",
      " [-5.27730056e-01]\n",
      " [-1.11656439e-01]\n",
      " [-6.66958380e-01]\n",
      " [ 6.52285837e-01]\n",
      " [ 1.45841162e-01]\n",
      " [ 3.49122182e-03]\n",
      " [ 8.57369959e-01]\n",
      " [-2.33060335e-01]\n",
      " [-3.12847917e-01]\n",
      " [ 5.03718382e-02]\n",
      " [-1.79413799e-01]\n",
      " [-3.14177710e-01]\n",
      " [ 1.00501164e+00]\n",
      " [-5.80373372e-02]\n",
      " [-8.28318152e-01]\n",
      " [ 2.67789393e-01]\n",
      " [-8.97938392e-03]\n",
      " [-1.71586645e-01]\n",
      " [-7.85399480e-01]\n",
      " [ 1.63038952e-01]\n",
      " [-4.53192345e-01]\n",
      " [-5.37975671e-01]\n",
      " [ 1.02006674e+00]\n",
      " [-5.91525471e-01]\n",
      " [-3.04772424e-01]\n",
      " [ 2.77927912e-02]\n",
      " [-1.32517535e-02]\n",
      " [-5.81307291e-01]\n",
      " [ 3.66283597e-01]\n",
      " [ 2.04478870e-02]\n",
      " [-8.46606328e-02]\n",
      " [ 3.00972134e-01]\n",
      " [ 4.30899122e-01]\n",
      " [ 9.20794292e-01]\n",
      " [ 2.20503043e-01]\n",
      " [ 1.72802632e+00]\n",
      " [-4.86223481e-01]\n",
      " [ 2.39347977e-02]\n",
      " [-4.73360146e-01]\n",
      " [ 2.13399403e-03]\n",
      " [-8.27925423e-01]\n",
      " [-4.01785231e-01]\n",
      " [ 1.32632752e-01]\n",
      " [-7.00658021e-01]\n",
      " [ 1.29973166e-01]\n",
      " [ 2.00075037e-02]\n",
      " [-3.31914336e-02]\n",
      " [ 1.14998651e+00]\n",
      " [-1.58047590e-01]\n",
      " [ 2.81872782e-01]\n",
      " [-1.42627192e-01]\n",
      " [ 1.06464271e-01]\n",
      " [-2.26804099e-01]\n",
      " [-4.58608252e-01]\n",
      " [-6.69707486e-01]\n",
      " [-5.02126128e-01]\n",
      " [-4.73201325e-01]\n",
      " [ 1.50039059e+00]\n",
      " [-2.53296009e-01]\n",
      " [-5.35977373e-01]\n",
      " [ 8.62964906e-01]\n",
      " [ 5.75157840e-01]\n",
      " [-5.10187190e-01]\n",
      " [ 3.03238990e-01]\n",
      " [-8.44089414e-01]\n",
      " [ 3.39784472e-01]\n",
      " [-6.64753608e-01]\n",
      " [-3.40773571e-01]\n",
      " [-9.87512375e-02]\n",
      " [-8.36242041e-01]\n",
      " [-6.51338723e-01]\n",
      " [-1.77050207e-01]\n",
      " [ 7.73257781e-02]\n",
      " [-7.51617536e-01]\n",
      " [-3.36707676e-01]\n",
      " [-6.37978708e-01]\n",
      " [-1.13948972e+00]\n",
      " [-4.68667612e-01]\n",
      " [ 3.01523683e-01]\n",
      " [-1.61699109e-01]\n",
      " [-2.01379211e-01]\n",
      " [-3.37204356e-01]\n",
      " [-9.54462236e-01]\n",
      " [-5.91132742e-01]\n",
      " [ 5.65374255e-01]\n",
      " [ 1.52502280e+00]\n",
      " [-3.16044622e-01]\n",
      " [ 8.97566960e-01]\n",
      " [ 4.11255436e-01]\n",
      " [-8.50310999e-01]\n",
      " [-4.82517092e-01]\n",
      " [ 2.31340646e-01]\n",
      " [-6.02129165e-01]\n",
      " [-9.52767149e-01]\n",
      " [ 4.76539465e-01]\n",
      " [ 1.18568445e+00]\n",
      " [-9.81722530e-02]\n",
      " [ 1.65935933e+00]\n",
      " [ 2.39016195e-01]\n",
      " [-1.13870427e+00]\n",
      " [-1.58766893e-02]\n",
      " [-1.26972885e-01]\n",
      " [ 1.73388518e-01]\n",
      " [-8.27532694e-01]\n",
      " [ 3.91545093e-02]\n",
      " [ 7.56457293e-01]\n",
      " [ 6.09001870e-01]\n",
      " [ 5.31819004e-01]\n",
      " [-3.37169706e-01]\n",
      " [-1.53086497e-01]\n",
      " [-6.02521895e-01]\n",
      " [-4.81297038e-01]\n",
      " [-8.27925423e-01]\n",
      " [-5.05998553e-01]\n",
      " [ 4.92283292e-01]\n",
      " [-1.11766178e-01]\n",
      " [ 4.07300707e-01]\n",
      " [-8.75825407e-01]\n",
      " [-4.51228698e-01]\n",
      " [-1.57525192e-02]\n",
      " [-2.78837852e-01]\n",
      " [ 2.61533157e-01]\n",
      " [ 3.97020442e-01]\n",
      " [ 4.09925643e-01]\n",
      " [-2.96704146e-01]\n",
      " [-5.24160841e-01]\n",
      " [-1.63242592e-01]\n",
      " [ 1.39826051e-01]\n",
      " [-2.49671924e-01]\n",
      " [-6.29363452e-02]\n",
      " [-8.09123782e-02]\n",
      " [ 6.15347626e-01]\n",
      " [-8.47169164e-01]\n",
      " [ 1.95311943e+00]\n",
      " [-2.14594837e-01]\n",
      " [ 4.77593484e-01]\n",
      " [-8.35476802e-01]\n",
      " [ 1.23716930e-01]\n",
      " [ 2.39609211e+00]\n",
      " [ 5.54035672e+00]\n",
      " [ 3.46639912e-01]\n",
      " [ 1.89462699e-02]\n",
      " [ 4.03435498e-01]\n",
      " [-2.83998203e-01]\n",
      " [ 8.08560346e-01]\n",
      " [ 3.86471618e-01]\n",
      " [ 1.61928650e+00]\n",
      " [-1.30265432e+00]\n",
      " [ 7.44772146e-01]\n",
      " [ 2.90333789e-01]\n",
      " [-3.74768068e-02]\n",
      " [ 7.71430092e-01]\n",
      " [ 1.22973047e-02]\n",
      " [ 1.35326988e-01]\n",
      " [ 9.64071043e-01]\n",
      " [ 8.07382158e-01]\n",
      " [ 3.59607198e-01]\n",
      " [ 3.24798669e-01]\n",
      " [ 6.26530304e-01]\n",
      " [-2.20292307e-01]\n",
      " [-7.87638902e-01]\n",
      " [ 6.69083682e-01]\n",
      " [-1.54495990e-03]\n",
      " [ 8.47399830e-02]\n",
      " [-2.42368886e-01]\n",
      " [ 8.55716737e-01]\n",
      " [-3.56785957e-01]\n",
      " [ 3.17687674e-01]\n",
      " [ 1.23182726e+00]\n",
      " [ 1.36059049e+00]\n",
      " [-1.04754775e+00]\n",
      " [-5.19495742e-01]\n",
      " [ 4.68133327e-01]\n",
      " [-7.91566197e-01]\n",
      " [-7.14582589e-01]\n",
      " [ 2.81328448e-01]\n",
      " [ 8.41263481e-02]\n",
      " [-3.40229237e-01]\n",
      " [-2.18577001e-01]\n",
      " [-8.28832408e-02]\n",
      " [-6.62245627e-01]\n",
      " [-3.68960569e-01]\n",
      " [ 2.37838007e-01]\n",
      " [-1.52335689e-01]\n",
      " [ 4.66659145e-01]\n",
      " [-1.55077579e-01]\n",
      " [-4.93871595e-01]\n",
      " [-6.98538697e-02]\n",
      " [-2.65496839e-02]\n",
      " [-3.51046621e-01]\n",
      " [-6.02129165e-01]\n",
      " [-3.34276211e-01]\n",
      " [ 3.66477068e-01]\n",
      " [-1.86923311e-01]\n",
      " [-1.81308145e-01]\n",
      " [-8.36242041e-01]\n",
      " [ 1.04369259e+00]\n",
      " [-3.62373689e-01]\n",
      " [-8.35791799e-02]\n",
      " [ 7.38640080e-01]\n",
      " [-4.03803747e-01]\n",
      " [ 2.40649198e-01]\n",
      " [-6.51145253e-01]\n",
      " [ 2.10152634e+00]\n",
      " [ 4.04834592e-01]\n",
      " [ 6.00086048e-01]\n",
      " [-7.06280402e-01]\n",
      " [ 4.81038528e-01]\n",
      " [ 1.97317577e-01]\n",
      " [-4.54976952e-01]\n",
      " [-7.13563222e-01]\n",
      " [ 5.73007938e-01]\n",
      " [ 1.78494000e-01]\n",
      " [-2.12720710e-01]\n",
      " [-5.96977746e-02]\n",
      " [-5.43349712e-01]\n",
      " [-4.91425699e-01]\n",
      " [-7.77156735e-02]\n",
      " [-1.39602312e-01]\n",
      " [-5.69973008e-01]\n",
      " [ 4.18689860e-01]\n",
      " [-3.49234578e-01]\n",
      " [ 3.46199528e-01]\n",
      " [ 6.41158028e-01]\n",
      " [-3.68120240e-01]\n",
      " [ 4.46325019e-02]\n",
      " [-4.61529182e-01]\n",
      " [-5.91490821e-01]\n",
      " [-8.11630047e-01]\n",
      " [-7.19729938e-01]\n",
      " [ 3.87560286e-01]\n",
      " [ 1.49026193e+00]\n",
      " [-7.69200839e-01]\n",
      " [-8.09880089e-01]\n",
      " [-1.88329621e-01]\n",
      " [ 7.97529272e-01]\n",
      " [ 1.39826508e+00]\n",
      " [ 3.60854686e-01]\n",
      " [ 1.97792611e-01]\n",
      " [ 8.69104187e-01]\n",
      " [ 1.68267618e+00]\n",
      " [ 5.12292273e-01]\n",
      " [ 6.24569301e-02]\n",
      " [ 1.26376516e-01]\n",
      " [-9.42307844e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 推定\n",
    "y_pred_train = slr.predict(X_train_std)\n",
    "y_pred = slr.predict(X_test_std)\n",
    "print('y_pred:\\n',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_MSE： 1.5363726221674683\n",
      "Test_MSE： 1.5403275324011667\n",
      "切片： 0.23797996072844113\n",
      "係数： [0.60672967 0.17918622]\n"
     ]
    }
   ],
   "source": [
    "print('Train_MSE：',slr.MSE(y_pred_train,y_train_std))\n",
    "print('Test_MSE：',slr.MSE(y_pred,y_test_std))\n",
    "print('切片：',slr.coef_[0])\n",
    "print('係数：',slr.coef_[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ２．sklearnのLinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_MSE： 0.3230340002216025\n",
      "Test_MSE： 0.41002698832759593\n",
      "切片： -2.690696506883759\n",
      "係数： [0.53730804 5.67444994]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# 初期化，学習，推定\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_std,y_train_std)\n",
    "y_train_pred_sk = model.predict(X_train_std)\n",
    "y_pred_sk = model.predict(X_test_std)\n",
    "\n",
    "print('Train_MSE：',mean_squared_error(y_train_std,y_train_pred_sk))\n",
    "print('Test_MSE：',mean_squared_error(y_test_std,y_pred_sk))\n",
    "print('切片：',model.intercept_)\n",
    "print('係数：',model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】学習曲線のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.array(range(slr.iter)), slr.loss, label=\"loss\")\n",
    "plt.scatter(np.array(range(slr.iter)), slr.val_loss, label=\"val_loss\")\n",
    "\n",
    "plt.title(\"model loss\")\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
