{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ リカレントニューラルネットワーク\n",
    "# リカレントニューラルネットワークスクラッチ\n",
    "**リカレントニューラルネットワーク（RNN）** のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "フォワードプロパゲーションの実装を必須課題とし、バックプロパゲーションの実装はアドバンス課題とします。\n",
    "\n",
    "クラスの名前はScratchSimpleRNNClassifierとしてください。クラスの構造などは以前のSprintで作成したScratchDeepNeuralNetrowkClassifierを参考にしてください。\n",
    "\n",
    "# 【問題1】SimpleRNNのフォワードプロパゲーション実装\n",
    "SimpleRNNのクラスSimpleRNNを作成してください。基本構造はFCクラスと同じになります。\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。ndarrayのshapeがどうなるかを併記しています。\n",
    "\n",
    "バッチサイズをbatch_size、入力の特徴量数をn_features、RNNのノード数をn_nodesとして表記します。活性化関数はtanhとして進めますが、これまでのニューラルネットワーク同様にReLUなどに置き換えられます。\n",
    "$$a_t=x_t・W_x+h_{t-1}・W_h+B$$\n",
    "$$h_t=tanh(a_t)$$\n",
    "$a_t$：時刻tの活性化関数を通す前の状態 (batch_size, n_nodes)                     \n",
    "$h_t$：時刻tの状態・出力 (batch_size, n_nodes)            \n",
    "$x_t$：時刻tの入力 (batch_size, n_features)            \n",
    "$W_x$：入力に対する重み (n_features, n_nodes)           \n",
    "$h_{t-1}$： 時刻t-1の状態（前の時刻から伝わる順伝播） (batch_size, n_nodes)               \n",
    "$W_h$：状態に対する重み。 (n_nodes, n_nodes)           \n",
    "$B$：バイアス項 (n_nodes,)                 \n",
    "                             \n",
    "初期状態$h_0$は全て0とすることが多いですが、任意の値を与えることも可能です。               \n",
    "上記の処理を系列数n_sequences回繰り返すことになります。RNN全体への入力$x$は(batch_size, n_sequences, n_features)のような配列で渡されることになり、そこから各時刻の配列を取り出していきます。\n",
    "\n",
    "分類問題であれば、それぞれの時刻のhに対して全結合層とソフトマックス関数（またはシグモイド関数）を使用します。タスクによっては最後の時刻のhだけを使用することもあります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】小さな配列でのフォワードプロパゲーションの実験\n",
    "小さな配列でフォワードプロパゲーションを考えてみます。\n",
    "\n",
    "入力x、初期状態h、重みw_xとw_h、バイアスbを次のようにします。\n",
    "\n",
    "ここで配列xの軸はバッチサイズ、系列数、特徴量数の順番です。                        \n",
    "フォワードプロパゲーションの出力が次のようになることを作成したコードで確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T09:03:01.054013Z",
     "start_time": "2019-09-30T09:03:01.037413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]]) # (batch_size, n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T09:03:10.900655Z",
     "start_time": "2019-09-30T09:03:10.862941Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n",
    "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
    "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
    "#batch_size = x.shape[0] # 1  ここでいうbatch_sizeとは，シークエンスの数である\n",
    "#n_sequences = x.shape[1] # 3　ここでいうn_sequencesとは，シークエンスの長さ，要素の個数である\n",
    "#n_features = x.shape[2] # 2\n",
    "#n_nodes = w_x.shape[1] # 4\n",
    "h = np.zeros((1,4)) # (batch_size, n_nodes) ｈの初期値\n",
    "#h_t = np.zeros((batch_size,n_sequences,n_nodes)) #ｈの結果を入れる(batch_size,n_sequences,n_nodes)\n",
    "b = np.array([1, 1, 1, 1]) # (n_nodes,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T09:03:58.150638Z",
     "start_time": "2019-09-30T09:03:58.121161Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleRNN:\n",
    "    def __init__(self, w_x, w_h, h, b):\n",
    "        \"\"\"\n",
    "        Paramator\n",
    "        ---------\n",
    "        w_x : 入力に対する重み (n_features, n_nodes)\n",
    "        w_h : 状態に対する重み。 (n_nodes, n_nodes) \n",
    "        h   : 状態の初期値(batch_size, n_nodes)\n",
    "        b   : バイアス(n_nodes,) \n",
    "        \"\"\"\n",
    "        self.w_x = w_x #(n_features, n_nodes)\n",
    "        self.w_h = w_h #(n_nodes, n_nodes)\n",
    "        self.h = h\n",
    "        self.b = b     #(n_nodes,)\n",
    "    \n",
    "    def _tanh(self,a_t):\n",
    "        \"\"\"活性化関数：ハイパボリックタンジェント\"\"\"\n",
    "        return np.tanh(a_t)\n",
    "    \n",
    "    \n",
    "    def _forward(self,x):\n",
    "        \"\"\"\n",
    "        RNNのフォワードプロパゲーション\n",
    "        input\n",
    "        ------\n",
    "        x   : 入力． (batch_size, n_sequences, n_features)\n",
    "        \n",
    "        output\n",
    "        -------\n",
    "        h_t : 時刻tの状態・出力 (batch_size, n_sequences, n_nodes) \n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0] # 1\n",
    "        n_sequences = x.shape[1] # 3\n",
    "        n_features = x.shape[2] # 2\n",
    "        n_nodes = self.w_x.shape[1] # 4\n",
    "        \n",
    "        h_t = np.zeros((batch_size,n_sequences,n_nodes)) #ｈの結果を入れる(batch_size,n_sequences,n_nodes)\n",
    "        \n",
    "        for i in range(n_sequences):\n",
    "            if np.all(h_t):\n",
    "                a_0 = x[:,i,:]@self.w_x + self.h@self.w_h + self.b\n",
    "                h_t[:,i,:] = self._tanh(a_0)\n",
    "                break\n",
    "            # ２回目以降のループ\n",
    "            else:\n",
    "                a_t = x[:,i,:]@w_x + h_t[:,i-1,:]@self.w_h + self.b\n",
    "                h_t[:,i,:] = self._tanh(a_t)\n",
    "        \n",
    "        return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T09:04:37.556454Z",
     "start_time": "2019-09-30T09:04:37.535280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.76188798, 0.76213958, 0.76239095, 0.76255841],\n",
       "        [0.792209  , 0.8141834 , 0.83404912, 0.84977719],\n",
       "        [0.79494228, 0.81839002, 0.83939649, 0.85584174]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = SimpleRNN(w_x, w_h, h, b)\n",
    "h_t = rnn._forward(x)\n",
    "h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "896.667px",
    "left": "329.99px",
    "top": "109.722px",
    "width": "164.988px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
