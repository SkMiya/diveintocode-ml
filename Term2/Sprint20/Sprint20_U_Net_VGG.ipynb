{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Sprint20_U-Net_VGG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHNEtupsHpD7",
        "colab_type": "text"
      },
      "source": [
        "# Sprint20 セグメンテーション２\n",
        "# 【問題2】コードの書き換え\n",
        "エンコーダーにResNetが使用されていたコードをVGGに変更してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fy_mLGZHpED",
        "colab_type": "text"
      },
      "source": [
        "## １．データの準備\n",
        "### （１）kaggleデータを読み込む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98hwroBtHzyl",
        "colab_type": "code",
        "outputId": "c8146a87-87d6-45dd-f0c1-3fd738289cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.5)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.6.16)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUbDQR1SH6JV",
        "colab_type": "code",
        "outputId": "73c473ee-74f6-4654-cda7-adb123d235aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#ドライブをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVMYsN9jH9yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#kaggleフォルダを作る\n",
        "mkdir .kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozh711W7IFO3",
        "colab_type": "code",
        "outputId": "4d4f3ed0-822f-4865-e188-c4a5a279da8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ls -a"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m.\u001b[0m/  \u001b[01;34m..\u001b[0m/  \u001b[01;34m.config\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34m.kaggle\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsm2tbpyIIED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "token = {'username':'skmiya','key':'519950b8ff97535ab9911be9e2b8fffe'}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOIZ3sp3IKdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /content/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKXrEHiKINBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2yG3Qa2IQfU",
        "colab_type": "code",
        "outputId": "cc8c4649-b2cf-412b-9ee4-7af645bbc3c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "#ファイルをダウンロード\n",
        "!kaggle competitions download -c tgs-salt-identification-challenge"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading depths.csv to /content\n",
            "  0% 0.00/322k [00:00<?, ?B/s]\n",
            "100% 322k/322k [00:00<00:00, 44.0MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/264k [00:00<?, ?B/s]\n",
            "100% 264k/264k [00:00<00:00, 85.4MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/922k [00:00<?, ?B/s]\n",
            "100% 922k/922k [00:00<00:00, 62.6MB/s]\n",
            "Downloading test.zip to /content\n",
            " 91% 149M/163M [00:01<00:00, 89.3MB/s]\n",
            "100% 163M/163M [00:01<00:00, 94.1MB/s]\n",
            "Downloading train.zip to /content\n",
            " 87% 33.0M/37.9M [00:00<00:00, 49.8MB/s]\n",
            "100% 37.9M/37.9M [00:00<00:00, 77.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70DldBulITFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trainを解凍\n",
        "!unzip /content/train.zip -d train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v-LxjFlIazt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testを解凍\n",
        "!unzip /content/test.zip -d test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny2zR_MdHpD8",
        "colab_type": "code",
        "outputId": "0588a852-b591-4fff-e346-f73b8d519adb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import gc\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.callbacks import *\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgMKzMiVHpD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (12, 9)\n",
        "# plt.style.use('ggplot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t28aaqdHpED",
        "colab_type": "code",
        "outputId": "7f1d512e-74b2-408d-d09c-752f78a15448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/sample_submission.csv')\n",
        "\n",
        "depth = pd.read_csv('/content/depths.csv')\n",
        "\n",
        "train_src = '/content/train'\n",
        "\n",
        "print('train:\\n{}'.format(train.head()))\n",
        "print('\\ntest:\\n{}'.format(test.head()))\n",
        "\n",
        "train = train.merge(depth, how='left', on='id')\n",
        "test = test.merge(depth, how='left', on='id')\n",
        "\n",
        "print('\\n{}'.format(train.head()))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:\n",
            "           id                                           rle_mask\n",
            "0  575d24d81d                                                NaN\n",
            "1  a266a2a9df                                          5051 5151\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
            "\n",
            "test:\n",
            "           id rle_mask\n",
            "0  155410d6fa      1 1\n",
            "1  78b32781d1      1 1\n",
            "2  63db2a476a      1 1\n",
            "3  17bfcdb967      1 1\n",
            "4  7ea0fd3c88      1 1\n",
            "\n",
            "           id                                           rle_mask    z\n",
            "0  575d24d81d                                                NaN  843\n",
            "1  a266a2a9df                                          5051 5151  794\n",
            "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
            "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
            "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJdL9y38HpEG",
        "colab_type": "code",
        "outputId": "4da610b1-f1a2-4c15-b822-d2297e851c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train = np.asarray(\n",
        "    [cv2.imread('/content/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
        "    dtype=np.uint8) / 255.\n",
        "y_train = np.asarray(\n",
        "    [cv2.imread('/content/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
        "    dtype=np.uint8) / 255.\n",
        "\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 101, 101) (4000, 101, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWx2HOm_HpEF",
        "colab_type": "text"
      },
      "source": [
        "### （２）データを見てみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vYqW3UmtHpEH",
        "colab_type": "code",
        "outputId": "c6348cd2-ce67-464e-d991-30eb34a3d1a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "random_index = np.random.randint(0, X_train.shape[0])\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "ax[0].imshow(X_train[random_index], cmap='gray')\n",
        "ax[1].imshow(y_train[random_index], cmap='gray')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fea82b53668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZKkDjbNkiRJUod/b1u2azRWRbUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-N-cOEeHpEJ",
        "colab_type": "text"
      },
      "source": [
        "### （３）ソルトカバレッジを計算\n",
        "これは、階層化された分割の基礎として機能します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FOdURP_HpEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = compute_coverage(train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGzhUAz-HpEL",
        "colab_type": "text"
      },
      "source": [
        "### （４）トレーニング用データの準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiDX9gTeHpEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_coverage(df, masks):\n",
        "    \n",
        "    df = df.copy()\n",
        "    \n",
        "    def cov_to_class(val):\n",
        "        for i in range(0, 11):\n",
        "            if val * 10 <= i:\n",
        "                return i\n",
        "\n",
        "    # Output percentage of area covered by class\n",
        "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
        "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
        "    # because each coverage will occur only once.\n",
        "    df['coverage_class'] = df.coverage.map(\n",
        "        cov_to_class)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_depth_abs_channels(image_tensor):\n",
        "    image_tensor = image_tensor.astype(np.float32)\n",
        "    h, w, c = image_tensor.shape\n",
        "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
        "        image_tensor[row, :, 1] = const\n",
        "    image_tensor[:, :, 2] = (\n",
        "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
        "\n",
        "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
        "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
        "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
        "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
        "\n",
        "    return image_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfH9GwG9HpEM",
        "colab_type": "code",
        "outputId": "a0ea1f7f-39a2-4dcb-9b43-467bc579d56e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
        "\n",
        "# Add channel features\n",
        "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
        "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
        "\n",
        "# Resize to 224x224, default ResNet50 image size\n",
        "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
        "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
        "\n",
        "\n",
        "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
        "    \n",
        "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
        "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
        "    \n",
        "    break\n",
        "    \n",
        "\n",
        "y_tr = np.expand_dims(y_tr, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "\n",
        "print(X_tr.shape, y_tr.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "del X_train_ch, y_resized\n",
        "del X_resized\n",
        "gc.collect()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
            "(804, 224, 224, 3) (804, 224, 224, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm5RWNUcHpEN",
        "colab_type": "text"
      },
      "source": [
        "## ２．関数定義\n",
        "### （１）Loss functions & metric:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZfRDZ67HpEO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "\n",
        "# Dice & combined\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = y_true_f * y_pred_f\n",
        "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return 1. - score\n",
        "\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "def bce_logdice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    \"\"\"\n",
        "    gts = tf.reduce_sum(gt_sorted)\n",
        "    intersection = gts - tf.cumsum(gt_sorted)\n",
        "    union = gts + tf.cumsum(1. - gt_sorted)\n",
        "    jaccard = 1. - intersection / union\n",
        "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "# --------------------------- BINARY LOSSES ---------------------------\n",
        "\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        def treat_image(log_lab):\n",
        "            log, lab = log_lab\n",
        "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
        "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
        "            return lovasz_hinge_flat(log, lab)\n",
        "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
        "        loss = tf.reduce_mean(losses)\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss():\n",
        "        labelsf = tf.cast(labels, logits.dtype)\n",
        "        signs = 2. * labelsf - 1.\n",
        "        errors = 1. - logits * tf.stop_gradient(signs)\n",
        "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
        "        gt_sorted = tf.gather(labelsf, perm)\n",
        "        grad = lovasz_grad(gt_sorted)\n",
        "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
        "        return loss\n",
        "\n",
        "    # deal with the void prediction case (only void pixels)\n",
        "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
        "                   lambda: tf.reduce_sum(logits) * 0.,\n",
        "                   compute_loss,\n",
        "                   strict=True,\n",
        "                   name=\"loss\"\n",
        "                   )\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "    \"\"\"\n",
        "    scores = tf.reshape(scores, (-1,))\n",
        "    labels = tf.reshape(labels, (-1,))\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = tf.not_equal(labels, ignore)\n",
        "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
        "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
        "    return vscores, vlabels\n",
        "\n",
        "\n",
        "def lovasz_loss(y_true, y_pred):\n",
        "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
        "    #logits = K.log(y_pred / (1. - y_pred))\n",
        "    logits = y_pred #Jiaxin\n",
        "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# IoU metric for observation during training\n",
        "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
        "def get_iou_vector(A, B):\n",
        "    # Numpy version    \n",
        "    batch_size = A.shape[0]\n",
        "    metric = 0.0\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch], B[batch]\n",
        "        true = np.sum(t)\n",
        "        pred = np.sum(p)\n",
        "        \n",
        "        # deal with empty mask first\n",
        "        if true == 0:\n",
        "            metric += (pred == 0)\n",
        "            continue\n",
        "        \n",
        "        # non empty mask case.  Union is never empty \n",
        "        # hence it is safe to divide by its number of pixels\n",
        "        intersection = np.sum(t * p)\n",
        "        union = true + pred - intersection\n",
        "        iou = intersection / union\n",
        "        \n",
        "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
        "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
        "        \n",
        "        metric += iou\n",
        "        \n",
        "    # teake the average over all images in batch\n",
        "    metric /= batch_size\n",
        "    return metric\n",
        "\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
        "\n",
        "\n",
        "# For Lovash loss\n",
        "def my_iou_metric_2(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyfaR1eKCf6K",
        "colab_type": "text"
      },
      "source": [
        "### （２）IOU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvKOdyHDHpEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOF6nvppCwis",
        "colab_type": "text"
      },
      "source": [
        "### （３）デコーダーブロック"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ6zDhqMHpER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic decoder block with Conv, BN and PReLU activation.\n",
        "def decoder_block_simple(\n",
        "    layer_name, block_name,\n",
        "    num_filters=32,\n",
        "    conv_dim=(3, 3)):\n",
        "  \n",
        "  x_dec = Conv2D(\n",
        "      num_filters, conv_dim,\n",
        "      padding='same',\n",
        "      name='{}_conv'.format(block_name))(layer_name)\n",
        "  x_dec = BatchNormalization(\n",
        "      name='{}_bn'.format(block_name))(x_dec)\n",
        "  x_dec = PReLU(\n",
        "      name='{}_activation'.format(block_name))(x_dec)\n",
        "      \n",
        "  return x_dec\n",
        "\n",
        "# Decoder block with bottleneck architecture, where middle conv layer\n",
        "# is half the size of first and last, in order to compress representation.\n",
        "# This type of architecture is supposed to retain most useful information.\n",
        "def decoder_block_bottleneck(\n",
        "    layer_name, block_name,\n",
        "    num_filters=32,\n",
        "    conv_dim=(3, 3),\n",
        "    dropout_frac=0.2):\n",
        "  \n",
        "  x_dec = Conv2D(\n",
        "      num_filters, conv_dim,\n",
        "      padding='same',\n",
        "      name='{}_conv1'.format(block_name))(layer_name)\n",
        "  x_dec = BatchNormalization(\n",
        "      name='{}_bn1'.format(block_name))(x_dec)\n",
        "  x_dec = PReLU(\n",
        "      name='{}_activation1'.format(block_name))(x_dec)\n",
        "  x_dec = Dropout(dropout_frac)(x_dec)\n",
        "\n",
        "  x_dec2 = Conv2D(\n",
        "      num_filters // 2, conv_dim,\n",
        "      padding='same',\n",
        "      name='{}_conv2'.format(block_name))(x_dec)\n",
        "  x_dec2 = BatchNormalization(\n",
        "      name='{}_bn2'.format(block_name))(x_dec2)\n",
        "  x_dec2 = PReLU(\n",
        "      name='{}_activation2'.format(block_name))(x_dec2)\n",
        "  x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "  x_dec2 = Conv2D(\n",
        "      num_filters, conv_dim,\n",
        "      padding='same',\n",
        "      name='{}_conv3'.format(block_name))(x_dec2)\n",
        "  x_dec2 = BatchNormalization(\n",
        "      name='{}_bn3'.format(block_name))(x_dec2)\n",
        "  x_dec2 = PReLU(\n",
        "      name='{}_activation3'.format(block_name))(x_dec2)\n",
        "  x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
        "\n",
        "  x_dec2 = Add()([x_dec, x_dec2])\n",
        "\n",
        "  return x_dec2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKBvJT--QzWX",
        "colab_type": "text"
      },
      "source": [
        "# 【問題2】コードの書き換え\n",
        "エンコーダーにResNetが使用されていたコードをVGGに変更してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfe0auNdMtiw",
        "colab_type": "code",
        "outputId": "d27aae0b-3285-46b3-bc28-f8dd66c2a911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# VGG19の層の確認\n",
        "from keras.applications.vgg19 import VGG19\n",
        "input_size = (224, 224, 3)\n",
        "K.clear_session()\n",
        "VGG_model = VGG19(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights='imagenet')\n",
        "VGG_model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 2s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lu7oSUR_ExV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# エンコーダ部分をVGG19に変える\n",
        "def unet_VGG(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "    \n",
        "    # Encoder part\n",
        "    # ベースモデルをVGG19に\n",
        "    base_model = VGG19(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    \n",
        "    # プーリングの手前のレイヤのアウトプットをデコーダー部分でconcateするために保存\n",
        "    encoder1 = base_model.get_layer('block1_conv2').output # (224,224,64)\n",
        "    encoder2 = base_model.get_layer('block2_conv2').output # (112,112,228)\n",
        "    encoder3 = base_model.get_layer('block3_conv4').output # (56,56,256)\n",
        "    encoder4 = base_model.get_layer('block4_conv4').output # (28,28,512)\n",
        "    encoder5 = base_model.get_layer('block5_conv4').output # (14,14,512)\n",
        "\n",
        "    # Center block\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1) # (14,14,1024)\n",
        "\n",
        "    # Decoder part.\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256) #(14,14,256)　256個のフィルタで畳み込んでチャネルを減らす\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1) #(28,28,256) + (28,28,512) = (28,28,768)\n",
        "    # ↑(14,14,256)をアップサンプリングして，(28,28,256)にしてる．\n",
        "    \n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128) # (28,28,128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1) # (56,56,,128) + (56,56,256)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    #output = UpSampling2D()(concat1)\n",
        "    #output = Conv2D(2, 32, activation = None, padding = 'same')(concat1)\n",
        "    output = decoder_block(\n",
        "        concat1, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CnjPzZpXQJz",
        "colab_type": "code",
        "outputId": "1fa9f673-f3e0-401e-c97a-0312c8b36a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#summaryを見る\n",
        "input_size = (224, 224, 3)\n",
        "\n",
        "K.clear_session()\n",
        "model = unet_VGG(\n",
        "    input_size, decoder_block_simple, weights='imagenet')\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From <ipython-input-22-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_conv (Conv2D)            (None, 14, 14, 512)  2359808     block5_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_bn (BatchNormalization)  (None, 14, 14, 512)  2048        center_conv[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_activation (PReLU)       (None, 14, 14, 512)  100352      center_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           center_activation[0][0]          \n",
            "                                                                 block5_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv (Conv2D)          (None, 14, 14, 256)  2359552     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn (BatchNormalization (None, 14, 14, 256)  1024        decoder4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation (PReLU)     (None, 14, 14, 256)  50176       decoder4_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0           decoder4_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 28, 28, 768)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 block4_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv (Conv2D)          (None, 28, 28, 128)  884864      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn (BatchNormalization (None, 28, 28, 128)  512         decoder3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation (PReLU)     (None, 28, 28, 128)  100352      decoder3_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0           decoder3_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 56, 56, 384)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 block3_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv (Conv2D)          (None, 56, 56, 64)   221248      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn (BatchNormalization (None, 56, 56, 64)   256         decoder2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation (PReLU)     (None, 56, 56, 64)   200704      decoder2_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64) 0           decoder2_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_3[0][0]            \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv (Conv2D)          (None, 112, 112, 64) 110656      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn (BatchNormalization (None, 112, 112, 64) 256         decoder1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation (PReLU)     (None, 112, 112, 64) 802816      decoder1_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64) 0           decoder1_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 224, 224, 2)  262146      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  3           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 27,481,157\n",
            "Trainable params: 27,479,109\n",
            "Non-trainable params: 2,048\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnWP4gxURGjb",
        "colab_type": "text"
      },
      "source": [
        "# 【問題3】学習・推定\n",
        "ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2sF-Y6-RRCr",
        "colab_type": "text"
      },
      "source": [
        "## １．VGG19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZPdK1zlXuXU",
        "colab_type": "code",
        "outputId": "9d87049e-d923-4a2e-87d9-d23c67b5d0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "model_depth = unet_VGG(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_VGG.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "epochs = 2  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From <ipython-input-22-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 14, 14, 512)  100352      center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 14, 14, 512)  0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 14, 14, 256)  1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 14, 14, 256)  1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 14, 14, 256)  50176       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 14, 14, 256)  0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 14, 14, 512)  1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 14, 14, 512)  2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 14, 14, 512)  100352      center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 14, 14, 512)  0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 14, 14, 512)  0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 14, 14, 1024) 0           add_1[0][0]                      \n",
            "                                                                 block5_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 14, 14, 256)  2359552     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 14, 14, 128)  295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 128)  512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 14, 14, 128)  25088       decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 14, 14, 128)  0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 14, 14, 256)  295168      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 14, 14, 256)  0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 28, 28, 768)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 block4_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 28, 28, 128)  884864      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 28, 28, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 28, 28, 64)   73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 28, 28, 64)   50176       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 28, 28, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 28, 28, 128)  73856       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 28, 28, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 128)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 56, 56, 384)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 block3_conv4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 56, 56, 64)   221248      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 56, 56, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 56, 56, 64)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 64) 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_3[0][0]            \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 112, 112, 64) 110656      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 112, 112, 32) 18464       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 112, 112, 32) 128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 112, 112, 32) 401408      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 112, 112, 32) 0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 112, 112, 64) 18496       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 112, 112, 64) 0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 64) 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 36,339,185\n",
            "Trainable params: 36,333,905\n",
            "Non-trainable params: 5,280\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 3196 samples, validate on 804 samples\n",
            "Epoch 1/2\n",
            "3196/3196 [==============================] - 300s 94ms/step - loss: 0.9235 - my_iou_metric: 0.1378 - val_loss: 0.9619 - val_my_iou_metric: 0.1769\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.17687, saving model to unet_VGG.h5\n",
            "Epoch 2/2\n",
            "3196/3196 [==============================] - 274s 86ms/step - loss: 0.7502 - my_iou_metric: 0.2436 - val_loss: 0.9663 - val_my_iou_metric: 0.2200\n",
            "\n",
            "Epoch 00002: val_my_iou_metric improved from 0.17687 to 0.22002, saving model to unet_VGG.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRwm52jFRy4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9vVNhX3STAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "#しきい値の最適化\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpJByMgmSbdW",
        "colab_type": "code",
        "outputId": "7c53f27b-2df1-4c56-ec12-8442991e6304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:46<00:00,  1.32s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmS2zoI9Sd8I",
        "colab_type": "code",
        "outputId": "05fbf81c-ca21-41f1-ce72-554cd849b8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.3154 at threshold: 0.860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.272779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.016106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.258458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.261256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.265299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.277052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.315423</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.272779\n",
              "std     0.204939   0.016106\n",
              "min     0.200000   0.258458\n",
              "25%     0.370000   0.261256\n",
              "50%     0.540000   0.265299\n",
              "75%     0.710000   0.277052\n",
              "max     0.880000   0.315423"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVVswHOYSiMl",
        "colab_type": "code",
        "outputId": "f66b1575-b99d-42cf-c1fd-4ddee9ea8473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fea2e5e2588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAIaCAYAAAA0thsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzCIiIiIiEfw/0J60FyDiAIYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKps_JlGSkle",
        "colab_type": "text"
      },
      "source": [
        "## ２．ResNet\n",
        "https://www.slideshare.net/KotaNagasato/resnet-82940994"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXc87HpiHpET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
        "# as this is an argument that can be given a function, like decoder_block_simple.\n",
        "def unet_resnet(input_size, decoder_block,\n",
        "                weights='imagenet',\n",
        "                loss_func='binary_crossentropy',\n",
        "                metrics_list=[my_iou_metric],\n",
        "                use_lovash=False):\n",
        "\n",
        "    # Base model - encoder\n",
        "    base_model = ResNet50(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights=weights)\n",
        "    \n",
        "    # Layers for feature extraction in the encoder part\n",
        "    encoder1 = base_model.get_layer('activation_1').output\n",
        "    encoder2 = base_model.get_layer('activation_10').output\n",
        "    encoder3 = base_model.get_layer('activation_22').output\n",
        "    encoder4 = base_model.get_layer('activation_40').output\n",
        "    encoder5 = base_model.get_layer('activation_49').output\n",
        "\n",
        "    # Center block\n",
        "    center = decoder_block(\n",
        "        encoder5, 'center', num_filters=512)\n",
        "    concat5 = concatenate([center, encoder5], axis=-1)\n",
        "\n",
        "    # Decoder part.\n",
        "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
        "    # This creates skip connections.\n",
        "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
        "    decoder4 = decoder_block(\n",
        "        concat5, 'decoder4', num_filters=256)\n",
        "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
        "\n",
        "    decoder3 = decoder_block(\n",
        "        concat4, 'decoder3', num_filters=128)\n",
        "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
        "\n",
        "    decoder2 = decoder_block(\n",
        "        concat3, 'decoder2', num_filters=64)\n",
        "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
        "\n",
        "    decoder1 = decoder_block(\n",
        "        concat2, 'decoder1', num_filters=64)\n",
        "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
        "\n",
        "    # Final upsampling and decoder block for segmentation.\n",
        "    output = UpSampling2D()(concat1)\n",
        "    output = decoder_block(\n",
        "        output, 'decoder_output', num_filters=32)\n",
        "    output = Conv2D(\n",
        "        1, (1, 1), activation=None, name='prediction')(output)\n",
        "    if not use_lovash:\n",
        "        output = Activation('sigmoid')(output)\n",
        "        \n",
        "    model = Model(base_model.input, output)\n",
        "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1Scrb4udLeZ",
        "colab_type": "code",
        "outputId": "16a98904-e000-482b-fe0a-8da5e0c82389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# ResNetの層の確認\n",
        "input_size = (224, 224, 3)\n",
        "K.clear_session()\n",
        "resnet_model = ResNet50(\n",
        "        input_shape=input_size, \n",
        "        include_top=False,\n",
        "        weights='imagenet')\n",
        "resnet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NI6GIFyHHpEV",
        "colab_type": "code",
        "outputId": "4d1ea7a3-07ee-4224-f3ba-dec76ac54163",
        "colab": {}
      },
      "source": [
        "input_size = (224, 224, 3)\n",
        "\n",
        "# U-Net ResNetのサマリーを見る\n",
        "K.clear_session()\n",
        "model = unet_resnet(\n",
        "    input_size, decoder_block_simple, weights='imagenet')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/w/anaconda3/envs/idp3exp/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 42,912,065\n",
            "Trainable params: 42,856,833\n",
            "Non-trainable params: 55,232\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "D5YwdgDkHpEX",
        "colab_type": "code",
        "outputId": "72085566-e1ad-49e4-df73-ff6dbdafeee4",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Build model:\n",
        "# Here, you can experiment with various losses.\n",
        "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
        "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
        "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
        "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
        "# This is controlled by use_lovash parameter.\n",
        "model_depth = unet_resnet(\n",
        "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
        "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
        "    use_lovash=False)\n",
        "print(model_depth.summary())\n",
        "\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
        "    save_best_only=True, save_weights_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_my_iou_metric',\n",
        "    mode='max',\n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    min_lr=0.0001, \n",
        "    verbose=1)\n",
        "\n",
        "\n",
        "epochs = 2  # 25\n",
        "batch_size = 16\n",
        "\n",
        "history = model_depth.fit(X_tr, y_tr,\n",
        "                    validation_data=[X_val, y_val], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[model_checkpoint,reduce_lr], \n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 48,978,353\n",
            "Trainable params: 48,919,953\n",
            "Non-trainable params: 58,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3196 samples, validate on 804 samples\n",
            "Epoch 1/2\n",
            "3196/3196 [==============================] - 118s 37ms/step - loss: 0.8196 - my_iou_metric: 0.3036 - val_loss: 1.3885 - val_my_iou_metric: 0.3580\n",
            "\n",
            "Epoch 00001: val_my_iou_metric improved from -inf to 0.35796, saving model to unet_resnet.h5\n",
            "Epoch 2/2\n",
            "3196/3196 [==============================] - 97s 30ms/step - loss: 0.5974 - my_iou_metric: 0.4705 - val_loss: 1.1928 - val_my_iou_metric: 0.2085\n",
            "\n",
            "Epoch 00002: val_my_iou_metric did not improve from 0.35796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYdV9wWXUhah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_preds = model_depth.predict(X_val, batch_size=16)\n",
        "\n",
        "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
        "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1J4tzhXHpEd",
        "colab_type": "code",
        "outputId": "d0cfa2ca-f29a-4b49-fdb7-1eb6f5367739",
        "colab": {}
      },
      "source": [
        "# Threshold range, over which optimization is performed\n",
        "thresholds = np.arange(0.2, 0.9, 0.02)\n",
        "\n",
        "# For every threshold, set predictions to binary arrays, \n",
        "# where values above threshold are treated as 1 and the rest as 0.\n",
        "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
        "ious = np.array(\n",
        "    [iou_metric_batch(y_val_true,\n",
        "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:35<00:00,  1.26s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADnvfexfHpEf",
        "colab_type": "code",
        "outputId": "b0f3c7ca-aa2a-43a7-cf05-43f16fd425f2",
        "colab": {}
      },
      "source": [
        "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
        "df_iou['iou'] = ious\n",
        "\n",
        "# Get index of best IoU\n",
        "best_index = df_iou['iou'].idxmax()\n",
        "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
        "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
        "\n",
        "# Describe IoU DF\n",
        "df_iou.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best IoU: 0.2805 at threshold: 0.880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>threshold</th>\n",
              "      <th>iou</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>35.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.223362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.204939</td>\n",
              "      <td>0.021597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.206841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.370000</td>\n",
              "      <td>0.209080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.211940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.228545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.280473</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       threshold        iou\n",
              "count  35.000000  35.000000\n",
              "mean    0.540000   0.223362\n",
              "std     0.204939   0.021597\n",
              "min     0.200000   0.206841\n",
              "25%     0.370000   0.209080\n",
              "50%     0.540000   0.211940\n",
              "75%     0.710000   0.228545\n",
              "max     0.880000   0.280473"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEfEeJDqHpEb",
        "colab_type": "text"
      },
      "source": [
        "### Threshold optimization: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erlOvzY9HpEi",
        "colab_type": "code",
        "outputId": "833293a5-4add-44e7-da54-542481587674",
        "colab": {}
      },
      "source": [
        "# Plot IoU values over threshold range.\n",
        "df_iou.plot(x='threshold', y='iou')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a593a98d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yM5rwn9GHvK",
        "colab_type": "text"
      },
      "source": [
        "# 結果\n",
        "ResNetの方が弱冠，IOUが高かった．                    \n",
        "層が深いから？？                     \n",
        "層が深い分，学習には時間がかかる．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gu5x7XQHpEl",
        "colab_type": "text"
      },
      "source": [
        "# メモ\n",
        "## Conv2D\n",
        "keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
        "## UpSampling2D\n",
        "2次元の入力に対するアップサンプリングレイヤー．データの行と列をそれぞれsize[0]及びsize[1]回繰り返します．\n",
        "keras.layers.UpSampling2D(size=(2, 2), data_format=None)                 \n",
        "**出力のshape**\n",
        "* data_format='channels_first'の場合， (batch, channels, upsampled_rows, upsampled_cols)の4階テンソル． \n",
        "* data_format='channels_last'の場合， (batch, upsampled_rows, upsampled_cols, channels)の4階テンソルになります                 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7ALDdBwHpEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}